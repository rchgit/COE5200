@article{Helstrom1967,
	abstract = {The restoration of optical images, as well as the unfolding of spectroscopic and other data that have been convolved with a window function or an instrumental impulse response, can be viewed as the solution of an integral equation. Solution of such an integral equation when the data are corrupted by noise or experimental error is treated as the problem of finding an estimate that is a linear functional of the data and minimizes the mean squared error between the true solution and itself. The estimate depends on assumptions about the spectral densities of the images and the noise, the choice of which is discussed. Coherent optical processing and digital processing are described.},
	author = {Helstrom, Carl W.},
	doi = {10.1364/JOSA.57.000297},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Journal of the Optical Society of America/1967\_Image Restoration by the Method of Least Squares.pdf:pdf},
	issn = {0030-3941},
	journal = {Journal of the Optical Society of America},
	number = {3},
	pages = {297},
	title = {{Image Restoration by the Method of Least Squares}},
	volume = {57},
	year = {1967}
}
@article{Sun2008,
	abstract = {In this paper, we propose an image super-resolution approach using a novel generic image prior - gradient profile prior, which is a parametric prior describing the shape and the sharpness of the image gradients. Using the gradient profile prior learned from a large number of natural images, we can provide a constraint on image gradients when we estimate a hi-resolution image from a low-resolution image. With this simple but very effective prior, we are able to produce state-of-the-art results. The reconstructed hi-resolution image is sharp while has rare ringing or jaggy artifacts.},
	author = {Sun, Jian and Sun, Jian and Xu, Zongben and Shum, Heung Yeung},
	doi = {10.1109/CVPR.2008.4587659},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR/2008\_Image super-resolution using gradient profile prior.pdf:pdf},
	isbn = {9781424422432},
	issn = {1063-6919},
	journal = {26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR},
	title = {{Image super-resolution using gradient profile prior}},
	year = {2008}
}
@article{Timofte2013a,
	abstract = {Recently there have been significant advances in image up scaling or $\backslash$nimage super-resolution based on a dictionary of low and high resolution $\backslash$nexemplars. The running time of the methods is often ignored despite the fact $\backslash$nthat it is a critical factor for real applications. This paper proposes fast $\backslash$nsuper-resolution methods while making no compromise on quality. First, we $\backslash$nsupport the use of sparse learned dictionaries in combination with neighbor $\backslash$nembedding methods. In this case, the nearest neighbors are computed using the $\backslash$ncorrelation with the dictionary atoms rather than the Euclidean distance. $\backslash$nMoreover, we show that most of the current approaches reach top performance for $\backslash$nthe right parameters. Second, we show that using global collaborative coding has $\backslash$nconsiderable speed advantages, reducing the super-resolution mapping to a $\backslash$nprecomputed projective matrix. Third, we propose the anchored neighborhood $\backslash$nregression. That is to anchor the neighborhood embedding of a low resolution $\backslash$npatch to the nearest atom in the dictionary and to precompute the corresponding $\backslash$nembedding matrix. These proposals are contrasted with current state-of-the-art $\backslash$nmethods on standard images. We obtain similar or improved quality and one or two $\backslash$norders of magnitude speed improvements.},
	author = {Timofte, R and De, V and {Van Gool}, L},
	doi = {10.1109/ICCV.2013.241},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Computer Vision (ICCV), 2013 IEEE International Conference on/2013\_Anchored Neighborhood Regression for Fast Example-Based Super-Resolution.pdf:pdf},
	isbn = {978-1-4799-2840-8},
	issn = {1550-5499},
	journal = {Computer Vision (ICCV), 2013 IEEE International Conference on},
	keywords = {image coding;image reconstruction;image resolution},
	pages = {1920--1927},
	title = {{Anchored Neighborhood Regression for Fast Example-Based Super-Resolution}},
	year = {2013}
}
@article{Zeyde2012,
	abstract = {This paper deals with the single image scale-up problem us- ing sparse-representation modeling. The goal is to recover an original image from its blurred and down-scaled noisy version. Since this problem is highly ill-posed, a prior is needed in order to regularize it. The liter- ature offers various ways to address this problem, ranging from simple linear space-invariant interpolation schemes (e.g., bicubic interpolation), to spatially-adaptive and non-linear filters of various sorts. We embark from a recently-proposed successful algorithm by Yang et. al. [13,14], and similarly assume a local Sparse-Land model on image patches, serving as regularization. Several important modifications to the above-mentioned solution are introduced, and are shown to lead to improved results. These modifications include a major simplification of the overall process both in terms of the computational complexity and the algorithm architecture, using a different training approach for the dictionary-pair, and introducing the ability to operate without a training- set by boot-strapping the scale-up task from the given low-resolution image. We demonstrate the results on true images, showing both visual and PSNR improvements.},
	author = {Zeyde, Roman and Elad, Michael and Protter, Matan},
	doi = {10.1007/978-3-642-27413-8\_47},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)/2012\_On single image scale-up using sparse-representations.pdf:pdf},
	isbn = {9783642274121},
	issn = {03029743},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	number = {1},
	pages = {711--730},
	title = {{On single image scale-up using sparse-representations}},
	volume = {6920 LNCS},
	year = {2012}
}
@article{Yang2010a,
	author = {Yang, Jianchao and Huang, Thomas},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Super-resolution imaging/2010\_Image super-resolution Historical overview and future challenges.pdf:pdf},
	isbn = {1439819319},
	journal = {Super-resolution imaging},
	title = {{Image super-resolution: Historical overview and future challenges}},
	url = {http://books.google.com/books?hl=en\&lr=\&id=fjTUbMnvOkgC\&oi=fnd\&pg=PA1\&dq=Image+super-resolution:+Historical+overview+and+future+challenges\&ots=53GZConOGy\&sig=oHgGJVo\_57Tv19cxLV\_XMtC1OPw},
	year = {2010}
}
@article{Yue2014,
	abstract = {In this paper, we present a locally adaptive regularized super-resolution model for images with mixed noise and outliers. The proposed method adaptively assigns the local norms in the data fidelity term of the regularized model. Specifically, it determines different norm values for different pixel locations, according to the impulse noise and motion outlier detection results. The L 1 norm is employed for pixels with impulse noise and motion outliers, and the L2 norm is used for the other pixels. In order to balance the difference in the constraint strength between the L1 norm and the L2 norm, a strategy to adaptively estimate a weighted parameter is put forward. The experimental results confirm the superiority of the proposed method for different images with mixed noise and outliers. © 2014 Elsevier B.V.},
	author = {Yue, Linwei and Shen, Huanfeng and Yuan, Qiangqiang and Zhang, Liangpei},
	doi = {10.1016/j.sigpro.2014.04.031},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Signal Processing/2014\_A locally adaptive L1-L2 norm for multi-frame super-resolution of images with mixed noise and outliers.pdf:pdf},
	issn = {01651684},
	journal = {Signal Processing},
	keywords = {Adaptive norm,Adaptive weight estimation,Mixed noise,Motion outliers,Super-resolution},
	pages = {156--174},
	publisher = {Elsevier},
	title = {{A locally adaptive L1-L2 norm for multi-frame super-resolution of images with mixed noise and outliers}},
	url = {http://dx.doi.org/10.1016/j.sigpro.2014.04.031},
	volume = {105},
	year = {2014}
}
@article{Farsiu2004,
	abstract = {Super-Resolution reconstruction produces one or a set of high-resolution images from a sequence of low-resolution frames. This article reviews a variety of Super-Resolution methods proposed in the last 20 years, and provides some insight into, and a summary of, our recent contributions to the general Super-Resolution problem. In the process, a detailed study of several very important aspects of Super-Resolution, often ignored in the literature, is presented. Specifically, we discuss robustness, treatment of color, and dynamic operation modes. Novel methods for addressing these issues are accompanied by experimental results on simulated and real data. Finally, some future challenges in Super-Resolution are outlined and discussed. 2004 Wiley Periodicals, Inc. Int J Imaging Syst Technol 14, 47-57, 2004; Published online in Wiley InterScience DOI 10.1002/ima.20007},
	author = {Farsiu, Sina and Robinson, Dirk and Elad, Michael and Milanfar, Peyman},
	doi = {10.1002/ima.20007},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/International Journal of Imaging Systems and Technology/2004\_Advances and challenges in super-resolution.pdf:pdf},
	isbn = {0899-9457},
	issn = {08999457},
	journal = {International Journal of Imaging Systems and Technology},
	keywords = {Demosaicing,Dynamic Super-Resolution,Image-reconstruction,Inverse problem,Robust estimation,Robust regularization,Super-Resolution},
	number = {2},
	pages = {47--57},
	pmid = {20031399},
	title = {{Advances and challenges in super-resolution}},
	volume = {14},
	year = {2004}
}
@article{Yang2013,
	abstract = {We propose a fast regression model for practical single image $\backslash$nsuper-resolution based on in-place examples, by leveraging two fundamental $\backslash$nsuper-resolution approaches- learning from an external database and learning $\backslash$nfrom self-examples. Our in-place self-similarity refines the recently proposed $\backslash$nlocal self-similarity by proving that a patch in the upper scale image have good $\backslash$nmatches around its origin location in the lower scale image. Based on the $\backslash$nin-place examples, a first-order approximation of the nonlinear mapping function $\backslash$nfrom low-to high-resolution image patches is learned. Extensive experiments on $\backslash$nbenchmark and real-world images demonstrate that our algorithm can produce $\backslash$nnatural-looking results with sharp edges and preserved fine details, while the $\backslash$ncurrent state-of-the-art algorithms are prone to visual artifacts. Furthermore, $\backslash$nour model can easily extend to deal with noise by combining the regression $\backslash$nresults on multiple in-place examples for robust estimation. The algorithm runs $\backslash$nfast and is particularly useful for practical applications, where the input $\backslash$nimages typically contain diverse textures and they are potentially contaminated $\backslash$nby noise or compression artifacts.},
	author = {Yang, Jianchao and Lin, Zhe and Cohen, Scott},
	doi = {10.1109/CVPR.2013.141},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition/2013\_Fast image super-resolution based on in-place example regression.pdf:pdf},
	isbn = {978-0-7695-4989-7},
	issn = {10636919},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer  Vision and Pattern Recognition},
	keywords = {image restoration,image upscaling,in-place matching,self-example,self-similarity,super-resolution},
	pages = {1059--1066},
	title = {{Fast image super-resolution based on in-place example regression}},
	year = {2013}
}
@article{Yang2010,
	abstract = {This paper presents a new approach to single-image superresolution, based upon sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low-resolution and high-resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low-resolution image patch can be applied with the high-resolution image patch dictionary to generate a high-resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs , reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super-resolution (SR) and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle SR with noisy inputs in a more unified framework.},
	author = {Yang, Jianchao and Wright, J. and Huang, T.S. and Ma, Yi},
	doi = {10.1109/TIP.2010.2050625},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2010\_Image Super-Resolution Via Sparse Representation.pdf:pdf},
	isbn = {1057-7149 VO  - 19},
	issn = {1057-7149},
	journal = {IEEE Transactions on Image Processing},
	number = {11},
	pages = {2861--2873},
	pmid = {20483687},
	title = {{Image Super-Resolution Via Sparse Representation}},
	url = {http://ieeexplore.ieee.org/ielx5/83/5602158/05466111.pdf?tp=\&arnumber=5466111\&isnumber=5602158$\backslash$nhttp://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5466111},
	volume = {19},
	year = {2010}
}
@article{Hore2010,
	abstract = {In this paper, we analyse two well-known objective image quality metrics, the peak-signal-to-noise ratio (PSNR) as well as the structural similarity index measure (SSIM), and we derive a simple mathematical relationship between them which works for various kinds of image degradations such as Gaussian blur, additive Gaussian white noise, jpeg and jpeg2000 compression. A series of tests realized on images extracted from the Kodak database gives a better understanding of the similarity and difference between the SSIM and the PSNR.},
	author = {Hor\'{e}, Alain and Ziou, Djemel},
	doi = {10.1109/ICPR.2010.579},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings - International Conference on Pattern Recognition/2010\_Image quality metrics PSNR vs. SSIM.pdf:pdf},
	isbn = {9780769541099},
	issn = {10514651},
	journal = {Proceedings - International Conference on Pattern Recognition},
	keywords = {Image quality metrics,PSNR,SSIM},
	pages = {2366--2369},
	pmid = {5596999},
	title = {{Image quality metrics: PSNR vs. SSIM}},
	year = {2010}
}

@article{Dong2011,
	abstract = {As a powerful statistical image modeling technique, sparse representation has been successfully used in various image restoration applications. The success of sparse representation owes to the development of the l(1)-norm optimization techniques and the fact that natural images are intrinsically sparse in some domains. The image restoration quality largely depends on whether the employed sparse domain can represent well the underlying image. Considering that the contents can vary significantly across different images or different patches in a single image, we propose to learn various sets of bases from a precollected dataset of example image patches, and then, for a given patch to be processed, one set of bases are adaptively selected to characterize the local sparse domain. We further introduce two adaptive regularization terms into the sparse representation framework. First, a set of autoregressive (AR) models are learned from the dataset of example image patches. The best fitted AR models to a given patch are adaptively selected to regularize the image local structures. Second, the image nonlocal self-similarity is introduced as another regularization term. In addition, the sparsity regularization parameter is adaptively estimated for better image restoration performance. Extensive experiments on image deblurring and super-resolution validate that by using adaptive sparse domain selection and adaptive regularization, the proposed method achieves much better results than many state-of-the-art algorithms in terms of both PSNR and visual perception.},
	archivePrefix = {arXiv},
	arxivId = {1012.1184},
	author = {Dong, Weisheng and Zhang, Lei and Shi, Guangming and Wu, Xiaolin},
	doi = {10.1109/TIP.2011.2108306},
	eprint = {1012.1184},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2011\_Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization.pdf:pdf},
	isbn = {1057-7149},
	issn = {10577149},
	journal = {IEEE Transactions on Image Processing},
	keywords = {Deblurring,image restoration (IR),regularization,sparse representation,super-resolution},
	number = {7},
	pages = {1838--1857},
	pmid = {21278019},
	title = {{Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization}},
	volume = {20},
	year = {2011}
}
@article{Su2011,
	abstract = {Video super-resolution can be generally divided into two categories: incremental video super-resolution and simultaneous video super-resolution. Incremental video super-resolution algorithms are usually faster, but their results cannot be guaranteed to be visually consistent to the human vision system. An adaptive incremental video super-resolution framework with the temporal consistency constraint is proposed in this paper. The temporal consistency among the video frames is enforced by imposing the similarity between the adjacent reconstructed HR frames. The variances of the potential functions, which affect the weights of the different terms in the utility function, are adaptively determined so that the algorithm is robust to various motion and image content situations. Some considerations, such as the incremental motion estimation, are also incorporated to improve the efficiency of the algorithm, which makes the proposed algorithm near-realtime. The experimental results show that the proposed algorithm can generate HR video with high quality while saving the computational time as well.},
	author = {Su, Heng and Wu, Ying and Zhou, Jie},
	doi = {10.1109/ICIP.2011.6115632},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings - International Conference on Image Processing, ICIP/2011\_Adaptive incremental video super-resolution with temporal consistency.pdf:pdf},
	isbn = {9781457713033},
	issn = {15224880},
	journal = {Proceedings - International Conference on Image Processing, ICIP},
	keywords = {Video super-resolution,adaptive framework,human vision system,temporal consistency},
	pages = {1149--1152},
	title = {{Adaptive incremental video super-resolution with temporal consistency}},
	year = {2011}
}
@article{Su2013,
	abstract = {In this paper, the learning-based single image super-resolution (SR) is regarded as a problem of space structure learning. We propose a new SR method that identifies a space from the low-resolution (LR) image space that best preserves the structure of the high-resolution (HR) image space. The inference between the two structure-consistent spaces proves to be accurate and predicts HR image patches with higher quality. An effective iterative algorithm is also proposed to find the near-optimal solution to the model, which can be easily implemented in parallel computing. Extensive experiments are performed to show the effectiveness of the proposed algorithm. © 2013 Published by Elsevier B.V.},
	author = {Su, Heng and Jiang, Nan and Wu, Ying and Zhou, Jie},
	doi = {10.1016/j.patrec.2013.07.012},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Pattern Recognition Letters/2013\_Single image super-resolution based on space structure learning.pdf:pdf},
	issn = {01678655},
	journal = {Pattern Recognition Letters},
	keywords = {Metric learning,Single image super-resolution,Space structure learning},
	number = {16},
	pages = {2094--2101},
	publisher = {Elsevier B.V.},
	title = {{Single image super-resolution based on space structure learning}},
	url = {http://dx.doi.org/10.1016/j.patrec.2013.07.012},
	volume = {34},
	year = {2013}
}
@article{Hardie2007,
	abstract = {A computationally simple super-resolution algorithm using a type of adaptive Wiener filter is proposed. The algorithm produces an improved resolution image from a sequence of low-resolution (LR) video frames with overlapping field of view. The algorithm uses subpixel registration to position each LR pixel value on a common spatial grid that is referenced to the average position of the input frames. The positions of the LR pixels are not quantized to a finite grid as with some previous techniques. The output high-resolution (HR) pixels are obtained using a weighted sum of LR pixels in a local moving window. Using a statistical model, the weights for each HR pixel are designed to minimize the mean squared error and they depend on the relative positions of the surrounding LR pixels. Thus, these weights adapt spatially and temporally to changing distributions of LR pixels due to varying motion. Both a global and spatially varying statistical model are considered here. Since the weights adapt with distribution of LR pixels, it is quite robust and will not become unstable when an unfavorable distribution of LR pixels is observed. For translational motion, the algorithm has a low computational complexity and may be readily suitable for real-time and/or near real-time processing applications. With other motion models, the computational complexity goes up significantly. However, regardless of the motion model, the algorithm lends itself to parallel implementation. The efficacy of the proposed algorithm is demonstrated here in a number of experimental results using simulated and real video sequences. A computational analysis is also presented.},
	author = {Hardie, Russell},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE transactions on image processing a publication of the IEEE Signal Processing Society/2007\_A fast image super-resolution algorithm using an adaptive Wiener filter.pdf:pdf},
	issn = {1057-7149},
	journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
	number = {12},
	pages = {2953--2964},
	pmid = {18092595},
	title = {{A fast image super-resolution algorithm using an adaptive Wiener filter.}},
	volume = {16},
	year = {2007}
}
@article{Dong2014,
	archivePrefix = {arXiv},
	arxivId = {1501.00092},
	author = {Dong, Chao and Loy, Chen Change and He, Kaiming},
	eprint = {1501.00092},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/arXiv preprint/2014\_Image Super-Resolution Using Deep Convolutional Networks.pdf:pdf},
	journal = {arXiv preprint},
	pages = {1--14},
	title = {{Image Super-Resolution Using Deep Convolutional Networks}},
	year = {2014}
}
@article{Li2012,
	abstract = {Blind image deblurring, aiming at obtaining the sharp image fromblurred one, is a widely existing prob- lem in image processing. Traditional image deblur- ring methods always use the deconvolution method to remove the blur kernel’s effect, however, deconvolu- tion is so sensitive to noise that inevitable artifacts al- ways exist in the deblurring results, even though regu- larity terms are introduced as constraints. In this pa- per, we propose a novel blind image deblurring method based on the sparse prior of dictionary pair, estimat- ing the sparse coefficient, sharp image and blur ker- nel alternately. The proposed method could avoid the deconvolution problem which is an ill-posed problem, and obtain the result with fewer artifacts. Compared with the state-of-the-art method, experimental results demonstrate that the proposedmethod could obtain bet- ter performance.},
	author = {Li, Haisen and Zhang, Yanning},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/International Conference on Pattern Recognition/2012\_Blind Image Deblurring Based on Sparse Prior of Dictionary Pair.pdf:pdf},
	isbn = {9784990644116},
	issn = {10514651},
	journal = {International Conference on Pattern Recognition},
	keywords = {Enhancement, Restoration and Filtering,Image and Video Processing,Statistical, Syntactic and Structural Pattern Reco},
	number = {Icpr},
	pages = {3054--3057},
	title = {{Blind Image Deblurring Based on Sparse Prior of Dictionary Pair}},
	year = {2012}
}
@article{Liu2014,
	abstract = {Although multiframe super resolution has been extensively studied in past decades, super resolving real-world video sequences still remains challenging. In existing systems, either the motion models are oversimplified or important factors such as blur kernel and noise level are assumed to be known. Such models cannot capture the intrinsic characteristics that may differ from one sequence to another. In this paper, we propose a Bayesian approach to adaptive video super resolution via simultaneously estimating underlying motion, blur kernel, and noise level while reconstructing the original high-resolution frames. As a result, our system not only produces very promising super resolution results outperforming the state of the art, but also adapts to a variety of noise levels and blur kernels. To further analyze the effect of noise and blur kernel, we perform a two-step analysis using the Cramer-Rao bounds. We study how blur kernel and noise influence motion estimation with aliasing signals, how noise affects super resolution with perfect motion, and finally how blur kernel and noise influence super resolution with unknown motion. Our analysis results confirm empirical observations, in particular that an intermediate size blur kernel achieves the optimal image reconstruction results.},
	author = {Liu, Ce and Sun, Deqing},
	doi = {10.1109/TPAMI.2013.127},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Pattern Analysis and Machine Intelligence/2014\_On bayesian adaptive video super resolution.pdf:pdf},
	isbn = {2012120962},
	issn = {01628828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Super resolution,aliasing,blur kernel,noise level,optical flow},
	number = {2},
	pages = {346--360},
	pmid = {24356354},
	title = {{On bayesian adaptive video super resolution}},
	volume = {36},
	year = {2014}
}
@article{Cho2009,
	abstract = {This paper presents a fast deblurring method that produces a deblur- ring result from a single image of moderate size in a few seconds. We accelerate both latent image estimation and kernel estimation in an iterative deblurring process by introducing a novel prediction step and working with image derivatives rather than pixel values. In the prediction step, we use simple image processing techniques to predict strong edges from an estimated latent image, which will be solely used for kernel estimation. With this approach, a compu- tationally efficient Gaussian prior becomes sufficient for deconvo- lution to estimate the latent image, as small deconvolution artifacts can be suppressed in the prediction. For kernel estimation, we for- mulate the optimization function using image derivatives, and ac- celerate the numerical process by reducing the number of Fourier transforms needed for a conjugate gradient method. We also show that the formulation results in a smaller condition number of the nu- merical system than the use of pixel values, which gives faster con- vergence. Experimental results demonstrate that our method runs an order of magnitude faster than previous work, while the deblur- ring quality is comparable. GPU implementation facilitates further speed-up, making our method fast enough for practical use.},
	author = {Cho, Sunghyun and Lee, Seungyong},
	doi = {10.1145/1618452.1618491},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/ACM Transactions on Graphics/2009\_Fast motion deblurring.pdf:pdf},
	isbn = {0730-0301},
	issn = {07300301},
	journal = {ACM Transactions on Graphics},
	keywords = {deblurring,image restoration,motion blur},
	number = {5},
	pages = {1},
	title = {{Fast motion deblurring}},
	volume = {28},
	year = {2009}
}
@article{He2011,
	abstract = {In this paper we address the problem of producing a high-resolution image from a single low-resolution image without any external training set. We propose a framework for both magnification and deblurring using only the original low-resolution image and its blurred version. In our method, each pixel is predicted by its neighbors through the Gaussian process regression. We show that when using a proper covariance function, the Gaussian process regression can perform soft clustering of pixels based on their local structures. We further demonstrate that our algorithm can extract adequate information contained in a single low-resolution image to generate a high-resolution image with sharp edges, which is comparable to or even superior in quality to the performance of other edge-directed and example-based super-resolution algorithms. Experimental results also show that our approach maintains high-quality performance at large magnifications.},
	author = {He, He and Siu, Wan-Chi},
	doi = {10.1109/CVPR.2011.5995713},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Cvpr 2011/2011\_Single image super-resolution using Gaussian process regression.pdf:pdf},
	isbn = {978-1-4577-0393-5},
	issn = {1063-6919},
	journal = {Cvpr 2011},
	pages = {449--456},
	title = {{Single image super-resolution using Gaussian process regression}},
	year = {2011}
}
@article{Cheng2013,
	abstract = {In this study, a classification-based video super-resolution method using artificial neural network (ANN) is proposed to enhance low-resolution (LR) to high-resolution (HR) frames. The proposed method consists of four main steps: classification, motion-trace volume collection, temporal adjustment, and ANN prediction. A classifier is designed based on the edge properties of a pixel in the LR frame to identify the spatial information. To exploit the spatio-temporal information, a motion-trace volume is collected using motion estimation, which can eliminate unfathomable object motion in the LR frames. In addition, temporal lateral process is employed for volume adjustment to reduce unnecessary temporal features. Finally, ANN is applied to each class to learn the complicated spatio-temporal relationship between LR and HR frames. Simulation results show that the proposed method successfully improves both peak signal-to-noise ratio and perceptual quality. © 2013 Elsevier B.V. All rights reserved.},
	author = {Cheng, Ming Hui and Hwang, Kao Shing and Jeng, Jyh Horng and Lin, Nai Wei},
	doi = {10.1016/j.sigpro.2013.02.013},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Signal Processing/2013\_Classification-based video super-resolution using artificial neural networks.pdf:pdf},
	issn = {01651684},
	journal = {Signal Processing},
	keywords = {Artificial neural network (ANN),Bilateral filter,Classification,Motion estimation,Super-resolution},
	number = {9},
	pages = {2612--2625},
	publisher = {Elsevier},
	title = {{Classification-based video super-resolution using artificial neural networks}},
	url = {http://dx.doi.org/10.1016/j.sigpro.2013.02.013},
	volume = {93},
	year = {2013}
}
@article{Xiong2010,
	abstract = {This paper proposes a robust single-image super-resolution method for enlarging low quality web image/video degraded by downsampling and compression. To simultaneously improve the resolution and perceptual quality of such web image/video, we bring forward a practical solution which combines adaptive regularization and learning-based super-resolution. The contribution of this work is twofold. First, we propose to analyze the image energy change characteristics during the iterative regularization process, i.e., the energy change ratio between primitive (e.g., edges, ridges and corners) and nonprimitive fields. Based on the revealed convergence property of the energy change ratio, appropriate regularization strength can then be determined to well balance compression artifacts removal and primitive components preservation. Second, we verify that this adaptive regularization can steadily and greatly improve the pair matching accuracy in learning-based super-resolution. Consequently, their combination effectively eliminates the quantization noise and meanwhile faithfully compensates the missing high-frequency details, yielding robust super-resolution performance in the compression scenario. Experimental results demonstrate that our solution produces visually pleasing enlargements for various web images/videos.},
	author = {Xiong, Zhiwei and Sun, Xiaoyan and Wu, Feng},
	doi = {10.1109/TIP.2010.2045707},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2010\_Robust web imagevideo super-resolution.pdf:pdf},
	isbn = {1941-0042 (Electronic)$\backslash$r1057-7149 (Linking)},
	issn = {10577149},
	journal = {IEEE Transactions on Image Processing},
	keywords = {Adaptive regularization,compression artifacts removal,energy change ratio,learning-based super-resolution (SR),primitive/nonprimitive field,web image/video},
	number = {8},
	pages = {2017--2028},
	pmid = {20236889},
	title = {{Robust web image/video super-resolution}},
	volume = {19},
	year = {2010}
}
@article{Wright2010,
	abstract = {This paper presents a new approach to single-image super-resolution, based on sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low resolution and high resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low resolution image patch can be applied with the high resolution image patch dictionary to generate a high resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs [1], reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super-resolution and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle super-resolution with noisy inputs in a more unified framework.},
	author = {Wright, John and Huang, Thomas and Yang, Jianchao and Ma, Yi},
	doi = {10.1109/TIP.2010.2050625},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE transactions on image processing a publication of the IEEE Signal Processing Society/2010\_Image Super-Resolution via Sparse Representation.pdf:pdf},
	isbn = {978-1-4244-2242-5},
	issn = {1941-0042},
	journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
	pages = {1--13},
	pmid = {20483687},
	title = {{Image Super-Resolution via Sparse Representation.}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/20483687$\backslash$nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587647},
	year = {2010}
}

@article{Caner2003,
	abstract = { In many surveillance video applications, it is of interest to recognize an object or a person, which occupies a small portion of a low-resolution, noisy video. This paper addresses the problem of super-resolution recovery of a region of interest from more than one low-resolution view of a scene recorded by multiple cameras. The multiple camera scenario alleviates the difficulty in registration of multiple frames of video that contain non-rigid or multiple object motion in the single camera case. With proper temporal registration of multiple videos, arbitrary scene motion can be handled. The success of super-resolution recovery from multiple views in real applications vitally depends on two factors: i) the accuracy of multiple view registration results, and ii) the accuracy of the camera and data acquisition model. We propose a system, which consists of a method for sub-pixel accurate spatio-temporal alignment of multiple video sequences for view registration and the projections onto convex sets method for super-resolution recovery. Experiments were implemented using two commercial analog video cameras, which do not perform on-board compression. Experimental results show that the super resolution recovery of dynamic scenes can be achieved as long as the multiple views of the scene can be registered with sub-pixel accuracy.},
	author = {Caner, G. and a.M. Tekalp and Heinzelman, W.},
	doi = {10.1109/ICME.2003.1220866},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)/2003\_Super resolution recovery for multi-camera surveillance imaging.pdf:pdf},
	isbn = {0-7803-7965-9},
	journal = {2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)},
	title = {{Super resolution recovery for multi-camera surveillance imaging}},
	volume = {1},
	year = {2003}
}

@article{Ishizaka2013,
	author = {Ishizaka, K. and Miyamoto, T. and Akimoto, S. and Iketani, a. and Hosomi, T. and Sakai, J.},
	doi = {10.1109/CoolChips.2013.6547918},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Symposium on Low-Power and High-Speed Chips - Proceedings for 2013 COOL Chips XVI/2013\_Power efficient realtime super resolution by virtual pipeline technique on a server with manycore coprocessors.pdf:pdf},
	isbn = {9781467357814},
	journal = {IEEE Symposium on Low-Power and High-Speed Chips - Proceedings for 2013 COOL Chips XVI},
	keywords = {Coprocessor,Manycore,Power Efficiency,Super Resolution},
	pages = {2--4},
	title = {{Power efficient realtime super resolution by virtual pipeline technique on a server with manycore coprocessors}},
	volume = {2},
	year = {2013}
}

@article{Zhang2010,
	abstract = {In many surveillance video applications, it is of interest to recognize a region of interest (ROI), which often occupies a small portion of a low-resolution, noisy video. This paper proposes an edge-preserving maximum a posteriori (MAP) estimation based super-resolution algorithm using a weighted directional Markov image prior model for a ROI from more than one low-resolution surveillance image. Conjugate gradient (CG) optimization based on standard operations on images is then developed to improve the computational efficiency of the algorithm. The proposed algorithm is tested on different series of surveillance images. The experimental results indicate that the proposed algorithm has considerable effectiveness in terms of both objective measurements and visual evaluation. ?? 2009 Elsevier B.V. All rights reserved.},
	author = {Zhang, Liangpei and Zhang, Hongyan and Shen, Huanfeng and Li, Pingxiang},
	doi = {10.1016/j.sigpro.2009.09.002},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Signal Processing/2010\_A super-resolution reconstruction algorithm for surveillance images.pdf:pdf},
	isbn = {0165-1684},
	issn = {01651684},
	journal = {Signal Processing},
	keywords = {CG,MAP,Super-resolution,Surveillance images},
	number = {3},
	pages = {848--859},
	publisher = {Elsevier},
	title = {{A super-resolution reconstruction algorithm for surveillance images}},
	url = {http://dx.doi.org/10.1016/j.sigpro.2009.09.002},
	volume = {90},
	year = {2010}
}

@article{tsai1984multiframe,
	title={Multiframe image restoration and registration},
	author={Tsai, RY and Huang, Thomas S},
	journal={Advances in computer vision and Image Processing},
	volume={1},
	number={2},
	pages={317--339},
	year={1984}
}

@article{Wu2011,
	abstract = {this paper presents a parallel algorithm designed for Super-resolution Image Reconstruction based on Compressive sensing in the ATI Stream platform. In the accelerating process, we select part of the serial program as the objects to be sped up according to the execution time of each stage, set appropriate parallel granularity to make full use of GPU's computational horsepower, and make a rational use of different kinds of memory space in GPU. At last, the result of the parallel algorithm is shown and analyzed. Compared to the serial algorithm, parallel algorithm has significantly accelerated results.},
	author = {Wu, Xifei and Xiang, Hui and Lu, Peng},
	doi = {10.1109/DMDCM.2011.10},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/2011 Workshop on Digital Media and Digital Content Management/2011\_A GPU Accelerated Algorithm for Compressive Sensing Based Image Super-Resolution.pdf:pdf},
	isbn = {978-0-7695-4413-7},
	journal = {2011 Workshop on Digital Media and Digital Content Management},
	keywords = {Compressive Sensing,GPU,Image Super-resolution,parallel computing},
	number = {60633030},
	pages = {198--202},
	title = {{A GPU Accelerated Algorithm for Compressive Sensing Based Image Super-Resolution}},
	year = {2011}
}

@article{Yue2014,
	abstract = {In this paper, we present a locally adaptive regularized super-resolution model for images with mixed noise and outliers. The proposed method adaptively assigns the local norms in the data fidelity term of the regularized model. Specifically, it determines different norm values for different pixel locations, according to the impulse noise and motion outlier detection results. The L 1 norm is employed for pixels with impulse noise and motion outliers, and the L2 norm is used for the other pixels. In order to balance the difference in the constraint strength between the L1 norm and the L2 norm, a strategy to adaptively estimate a weighted parameter is put forward. The experimental results confirm the superiority of the proposed method for different images with mixed noise and outliers. © 2014 Elsevier B.V.},
	author = {Yue, Linwei and Shen, Huanfeng and Yuan, Qiangqiang and Zhang, Liangpei},
	doi = {10.1016/j.sigpro.2014.04.031},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Signal Processing/2014\_A locally adaptive L1-L2 norm for multi-frame super-resolution of images with mixed noise and outliers.pdf:pdf},
	issn = {01651684},
	journal = {Signal Processing},
	keywords = {Adaptive norm,Adaptive weight estimation,Mixed noise,Motion outliers,Super-resolution},
	pages = {156--174},
	publisher = {Elsevier},
	title = {{A locally adaptive L1-L2 norm for multi-frame super-resolution of images with mixed noise and outliers}},
	url = {http://dx.doi.org/10.1016/j.sigpro.2014.04.031},
	volume = {105},
	year = {2014}
}
@book{Gokhale,
author = {Gokhale, Maya},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/Unknown\_Algorithm Acceleration with Reconfigurable Hardware.pdf:pdf},
isbn = {0387261052},
title = {{Algorithm Acceleration with Reconfigurable Hardware}}
}
@article{Engineering2008,
author = {Engineering, Bachelor O F},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2008\_Implementation of Fpga-Based Object Tracking Algorithm.pdf:pdf},
number = {April},
pages = {1--49},
title = {{Implementation of Fpga-Based Object Tracking Algorithm}},
year = {2008}
}
@article{Draper2000,
abstract = {This paper presents a high-level language for expressing image
processing algorithms, and an optimizing compiler that targets FPGAs.
The language is called SA-C, and this paper focuses on the language
features that 1) support image processing, and 2) enable efficient
compilation to FPGAs. It then describes the compilation process, in
which SA-C algorithms are translated into non-recursive data flow
graphs, which in turn are translated into VHDL. Finally, it presents
performance numbers for some well-known image processing routines,
written in SAC and automatically compiled to an Annapolis Microsystems
WildForce board with Xilinx 4036XL FPGAs},
author = {Draper, B. and Najjar, W. and Bohm, W. and Hammes, J. and Rinker, B. and Ross, C. and Chawathe, M. and Bins, J.},
doi = {10.1109/CAMP.2000.875981},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings Fifth IEEE International Workshop on Computer Architectures for Machine Perception/2000\_Compiling and optimizing image processing algorithms for FPGAs.pdf:pdf},
isbn = {0-7695-0740-9},
journal = {Proceedings Fifth IEEE International Workshop on Computer Architectures for Machine Perception},
title = {{Compiling and optimizing image processing algorithms for FPGAs}},
year = {2000}
}
@article{Maurya2007,
author = {Maurya, Shashi and Gupta, Isha},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2007\_Fpga Based Hardware Implementation of Advanced Encryption.pdf:pdf},
keywords = {"ijert",- dilation,erosion,fpga,median filtering},
number = {6},
pages = {2135--2137},
title = {{Fpga Based Hardware Implementation of Advanced Encryption}},
volume = {3},
year = {2007}
}
@article{North2011,
author = {North, Palmerston},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2011\_Implementing Image Processing on FPGAs.pdf:pdf},
number = {06},
title = {{Implementing Image Processing on FPGAs}},
year = {2011}
}
@article{Roth2011,
author = {Roth, Filip},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2011\_Using low cost FPGAs for realtime video processing.pdf:pdf},
title = {{Using low cost FPGAs for realtime video processing}},
year = {2011}
}

@article{Angelopoulou2008,
abstract = {Recent technological advances in imaging industry have lead to the production of imaging systems with high density pixel sensors. However, their long exposure times limit their applications to static images due to the motion blur effect. This work presents ...},
author = {Angelopoulou, Maria E. and Bouganis, Christos Savvas and Cheung, P. Y K and Constantinides, George a.},
doi = {10.1007/978-3-540-78610-8\_14},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)/2008\_FPGA-based real-time super-resolution on an adaptive image sensor.pdf:pdf},
isbn = {3540786090},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {125--136},
title = {{FPGA-based real-time super-resolution on an adaptive image sensor}},
volume = {4943 LNCS},
year = {2008}
}

@article{Angelopoulou2009,
abstract = {The high density image sensors of state-of-the-art imaging systems provide outputs with high spatial resolution, but require long exposure times. This limits their applicability, due to the motion blur effect. Recent technological advances have lead to adaptive image sensors that can combine several pixels together in real time to form a larger pixel. Larger pixels require shorter exposure times and produce high-frame-rate samples with reduced motion blur. This work proposes combining an FPGA with an adaptive image sensor to produce an output of high resolution both in space and time. The FPGA is responsible for the spatial resolution enhancement of the high-frame-rate samples using super-resolution (SR) techniques in real time. To achieve it, this article proposes utilizing the Iterative Back Projection (IBP) SR algorithm. The original IBP method is modified to account for the presence of noise, leading to an algorithm more robust to noise. An FPGA implementation of this algorithm is presented. The proposed architecture can serve as a general purpose real-time resolution enhancement system, and its performance is evaluated under various noise levels.},
author = {Angelopoulou, Maria E. and Bouganis, Christos-Savvas and Cheung, Peter Y. K. and Constantinides, George a.},
doi = {10.1145/1575779.1575782},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/ACM Transactions on Reconfigurable Technology and Systems/2009\_Robust Real-Time Super-Resolution on FPGA and an Application to Video Enhancement.pdf:pdf},
issn = {19367406},
journal = {ACM Transactions on Reconfigurable Technology and Systems},
number = {4},
pages = {1--29},
title = {{Robust Real-Time Super-Resolution on FPGA and an Application to Video Enhancement}},
volume = {2},
year = {2009}
}

@inproceedings{Shen2014,
	abstract = {Super resolution is a process to generate high-resolution images from their low-resolution versions. In many applications such as super-HD (4K) TV, super resolution has to be performed in real time. In this paper we propose a real-time image/video super-resolution algorithm, which achieves good performance at low computational cost via off-line learning of interpolation errors in different pixel contexts. The proposed algorithm consists of three stages: fast edge-guided interpolation to generate an initial HR estimation, GPU-aided de-convolution, and error feedback compensation. All three stages can be implemented with GPU to support real-time applications. Experiments demonstrate the competitive performance of the new real-time super-resolution algorithm in both PSNR and visual quality.},
	author = {Shen, Yuxiang and Wu, Xiaolin and Deng, Xiaowei},
	booktitle = {2014 IEEE Visual Communications and Image Processing Conference},
	doi = {10.1109/VCIP.2014.7051560},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/2014 IEEE Visual Communications and Image Processing Conference/2014\_GPU-aided real-time imagevideo super resolution based on error feedback.pdf:pdf},
	isbn = {978-1-4799-6139-9},
	keywords = {GPU-aided deconvolution,GPU-aided real-time image-video super resolution a,Graphics processing units,Image edge detection,Image resolution,Interpolation,PSNR,Real-time systems,Signal resolution,Streaming media,Super resolution,artificial neural network,error compensation,error feedback,error feedback compensation,fast edge-guided interpolation,graphics processing units,high-resolution image generation,image resolution,initial HR estimation,interpolation,interpolation errors,learning (artificial intelligence),low computational cost,machine learning,off-line learning,parallel computing,pixel contexts,super-HD TV,video signal processing,visual quality},
	month = dec,
	pages = {286--290},
	publisher = {IEEE},
	shorttitle = {Visual Communications and Image Processing Confere},
	title = {{GPU-aided real-time image/video super resolution based on error feedback}},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7051560},
	year = {2014}
}

@article{Sirowy2008,
	abstract = {Where do all the cycles go when microprocessor applications are implemented spatially as circuits on an FPGA? It is well established that certain sequential applications can be captured spatially and achieve breathtaking speedups when run on an FPGA, but why? Despite running at clock speeds orders of magnitude slower compared to their embedded processor equivalents, FPGA applications can "lose" enough cycles to create exceptionally fast spatially-oriented circuits. We profile and analyze three canonical applications amenable to FPGA speedup to quantify exactly where FPGAs gain that speedup. We compare the FPGA implementations to several idealized software platforms. The idealized software platforms give insight as to how FPGA implementations attain such dramatic speedups. We quantify the effects of parallelizing and pipelining instructions, streaming data, and eliminating the instruction fetch, showing exactly where the cycles are lost in an FPGA implementation. We also show how the memory interface to the FPGA will affect the performance. Our results show that custom memory interfaces are the most effective way at enabling much greater performance on the FPGA, and that memory interfaces traditional software use become a bottleneck when the FPGA uses the same interface. The results, though not surprising, provide a clearer and more intuitive understanding of the performance FPGAs can achieve, offering researchers and engineers alike a new angle to attack the task of parallelizing applications.},
	author = {Sirowy, Scott and Forin, Alessandro},
	file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Microsoft Research/2008\_Where's the Beef Why FPGAs Are So Fast.pdf:pdf},
	journal = {Microsoft Research},
	number = {September},
	title = {{Where's the Beef ? Why FPGAs Are So Fast}},
	year = {2008}
}