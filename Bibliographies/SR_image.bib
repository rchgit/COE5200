@article{Lagendijk1998,
author = {Lagendijk, R L and Biemond, J and Boekee, D E},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Trans.Acoustics, Speech, And Signal Processing/1998\_\{R\}egularized \{I\}terative \{I\}mage \{R\}estoration with \{R\}ing \{R\}eduction.pdf:pdf},
journal = {IEEE Trans.Acoustics, Speech, And Signal Processing},
number = {12},
pages = {1874\~{}--\~{}1887},
title = {{\{R\}egularized \{I\}terative \{I\}mage \{R\}estoration with \{R\}ing \{R\}eduction}},
volume = {36},
year = {1998}
}
@article{Farbman2008,
abstract = {Many recent computational photography techniques decompose an image into a piecewise smooth base layer, containing large scale variations in intensity, and a residual detail layer capturing the smaller scale details in the image. In many of these applications, it is important to control the spatial scale of the extracted details, and it is often desirable to manipulate details at multiple scales, while avoiding visual artifacts. In this paper we introduce a new way to construct edge-preserving multi-scale image decompositions. We show that current basedetail decomposition techniques, based on the bilateral filter, are limited in their ability to extract detail at arbitrary scales. Instead, we advocate the use of an alternative edge-preserving smoothing operator, based on the weighted least squares optimization framework, which is particularly well suited for progressive coarsening of images and for multi-scale detail extraction. After describing this operator, we show how to use it to construct edge-preserving multi-scale decompositions, and compare it to the bilateral filter, as well as to other schemes. Finally, we demonstrate the effectiveness of our edge-preserving decompositions in the context of LDR and HDR tone mapping, detail enhancement, and other applications.},
author = {Farbman, Zeev and Fattal, Raanan and Lischinski, Dani and Szeliski, Richard},
doi = {10.1145/1360612.1360666},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/ACM Transactions on Graphics/2008\_Edge-preserving decompositions for multi-scale tone and detail manipulation.pdf:pdf},
isbn = {9781450301121},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {acm reference format,bilateral filter,detail en-,digital darkroom,edge-preserving smoothing,hancement,high dynamic range,image abstrac-,multi-scale image decomposition,tion,tone mapping},
number = {3},
pages = {1},
pmid = {9744933},
title = {{Edge-preserving decompositions for multi-scale tone and detail manipulation}},
volume = {27},
year = {2008}
}
@article{Lin2014,
author = {Lin, Sina and Qin, Zengchang and Liao, Renjie and Wan, Tao},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2014\_A CONFIDENCE GROWING MODEL FOR SUPER-RESOLUTION Intelligent Computing and Machine Leaning Lab Yamaha Corporation , Hamamatsu , 430-.pdf:pdf},
isbn = {9781479957514},
pages = {3929--3933},
title = {{A CONFIDENCE GROWING MODEL FOR SUPER-RESOLUTION Intelligent Computing and Machine Leaning Lab Yamaha Corporation , Hamamatsu , 430-0904 , Japan Department of CSE , Chinese University of Hong Kong , China School of Biological Science and Medical Engineering}},
year = {2014}
}
@article{Elad2006,
abstract = {We address the image denoising problem, where zeromean white and homogeneous Gaussian additive noise should be removed from a given image. The approach taken is based on sparse and redundant representations over a trained dictionary. The proposed algorithm denoises the image, while simultaneously trainining a dictionary on its (corrupted) content using the K-SVD algorithm. As the dictionary training algorithm is limited in handling small image patches, we extend its deployment to arbitrary image sizes by defining a global image prior that forces sparsity over patches in every location in the image. We show how such Bayesian treatment leads to a simple and effective denoising algorithm, with state-of-the-art performance, equivalent and sometimes surpassing recently published leading alternative denoising methods.},
author = {Elad, Michael and Aharon, Michal},
doi = {10.1109/CVPR.2006.142},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition/2006\_Image denoising via learned dictionaries and sparse representation.pdf:pdf},
isbn = {0769525970},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {895--900},
title = {{Image denoising via learned dictionaries and sparse representation}},
volume = {1},
year = {2006}
}
@article{Malczewski2008,
abstract = {The MRI image reconstruction supported by Toeplitz-based iterative super-resolution algorithm is presented in the paper. It is shown that the approach improves MRI spatial resolution in cases when multi-blade sequences are used. The PROPELLER MRI method collects data from rectangular regions (blades) rotated around the origin of the k-space. Inter-blade patient motion is the premise for the use of super-resolution technique. Images obtained from sets of irregularly located frequency domain samples are combined into the high resolution MRI image. The super-resolution reconstruction replaces usually applied direct averaging of low-resolution images. Furthermore high order affine motion model has been applied.},
author = {Malczewski, Krzysztof and Stasinski, Ryszard},
doi = {10.1109/ICIP.2008.4711761},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings - International Conference on Image Processing, ICIP/2008\_Toeplitz-based iterative image fusion scheme for MRI.pdf:pdf},
isbn = {1424417643},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
keywords = {Image reconstruction,MRI,Super-resolution},
pages = {341--344},
title = {{Toeplitz-based iterative image fusion scheme for MRI}},
year = {2008}
}
@article{Teo1994,
abstract = {In this paper, we present a perceptual distortion measure that
predicts image integrity far better than mean-squared error. This
perceptual distortion measure is based an a model of human visual
processing that fits empirical measurements of the psychophysics of
spatial pattern detection. The model of human visual processing proposed
involves two major components: a steerable pyramid transform and
contrast normalization. We also illustrate the usefulness of the model
in predicting perceptual distortion in real images},
author = {Teo, P.C. and Heeger, D.J.},
doi = {10.1109/ICIP.1994.413502},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings of 1st International Conference on Image Processing/1994\_Perceptual image distortion.pdf:pdf},
isbn = {0-8186-6952-7},
journal = {Proceedings of 1st International Conference on Image Processing},
pages = {982--986},
title = {{Perceptual image distortion}},
volume = {2},
year = {1994}
}
@article{Park2003,
abstract = { A new approach toward increasing spatial resolution is required to overcome the limitations of the sensors and optics manufacturing technology. One promising approach is to use signal processing techniques to obtain an high-resolution (HR) image (or sequence) from observed multiple low-resolution (LR) images. Such a resolution enhancement approach has been one of the most active research areas, and it is called super resolution (SR) (or HR) image reconstruction or simply resolution enhancement. In this article, we use the term "SR image reconstruction" to refer to a signal processing approach toward resolution enhancement because the term "super" in "super resolution" represents very well the characteristics of the technique overcoming the inherent resolution limitation of LR imaging systems. The major advantage of the signal processing approach is that it may cost less and the existing LR imaging systems can be still utilized. The SR image reconstruction is proved to be useful in many practical cases where multiple frames of the same scene can be obtained, including medical imaging, satellite imaging, and video applications. The goal of this article is to introduce the concept of SR algorithms to readers who are unfamiliar with this area and to provide a review for experts. To this purpose, we present the technical review of various existing SR methodologies which are often employed. Before presenting the review of existing SR algorithms, we first model the LR image acquisition process.},
author = {Park, Sung Cheol and Park, Min Kyu and Kang, Moon G.},
doi = {10.1109/MSP.2003.1203207},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Signal Processing Magazine/2003\_Super-resolution image reconstruction A technical overview.pdf:pdf},
isbn = {9781424468935},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {3},
pages = {21--36},
pmid = {22109467},
title = {{Super-resolution image reconstruction: A technical overview}},
volume = {20},
year = {2003}
}
@article{Weken2002,
abstract = { Objective quality measures or measures of comparison are of great importance in the field of image processing. These measures can be useful for the evaluation and comparison of different algorithms; designed to solve a particular problem. For example, one of the possible applications is the comparison of different filters for image noise reduction. It is well-known that classical quality measures, such as the MSE (mean square error) or the PSNR (peak signal to noise ratio), do not always correspond to visual observations. Therefore, several researchers are - and have been - looking for new quality measures, better adapted to human perception. The existing similarity measures are all pixel-based, and have therefore not always satisfactory results. To cope with this drawback, we propose a similarity measure based on a neighbourhood, so that the relevant structures of the images are observed very well. The new similarity measure is designed especially for use in image processing.},
author = {Weken, D. Van Der and Nachtegael, M. and Kerre, E.E.},
doi = {10.1109/ICOSP.2002.1181155},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/6th International Conference on Signal Processing, 2002/2002\_Image quality evaluation.pdf:pdf},
isbn = {0-7803-7488-6},
journal = {6th International Conference on Signal Processing, 2002.},
pages = {2--5},
title = {{Image quality evaluation}},
volume = {1},
year = {2002}
}
@article{Gao2013,
author = {Gao, Junbin and Ryde, North},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2013\_RESTRICTED BOLTZMANN MACHINE APPROACH TO COUPLE DICTIONARY TRAINING FOR IMAGE SUPER-RESOLUTION School of Computing and Mathematics.pdf:pdf},
isbn = {9781479923410},
pages = {499--503},
title = {{RESTRICTED BOLTZMANN MACHINE APPROACH TO COUPLE DICTIONARY TRAINING FOR IMAGE SUPER-RESOLUTION School of Computing and Mathematics , Charles Sturt University CSIRO Mathematics , Informatics and Statistics School of Automation , Guangdong University of Tec}},
year = {2013}
}
@article{Yang2012,
abstract = {In this paper, we propose a novel coupled dictionary training method for single-image super-resolution (SR) based on patchwise sparse recovery, where the learned couple dictionaries relate the low- and high-resolution (HR) image patch spaces via sparse representation. The learning process enforces that the sparse representation of a low-resolution (LR) image patch in terms of the LR dictionary can well reconstruct its underlying HR image patch with the dictionary in the high-resolution image patch space. We model the learning problem as a bilevel opti- mization problem, where the optimization includes an ?1-norm minimization problemin its constraints. Implicit differentiation is employed to calculate the desired gradient for stochastic gradient descent. We demonstrate that our coupled dictionary learning method can outperform the existing joint dictionary training method both quantitatively and qualitatively. Furthermore, for real applications, we speed up the algorithm approximately 10 times by learning a neural network model for fast sparse infer- ence and selectively processing only those visually salient regions. Extensive experimental comparisons with state-of-the-art SR algorithms validate the effectiveness of our proposed approach.},
author = {Yang, Jianchao and Wang, Zhaowen and Lin, Zhe and Cohen, Scott and Huang, Thomas},
doi = {10.1109/TIP.2012.2192127},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2012\_Coupled dictionary training for image super-resolution.pdf:pdf},
isbn = {1057-7149},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Dictionary learning,image restoration,image super-resolution,sparse coding,sparse recovery},
number = {8},
pages = {3467--3478},
pmid = {22481818},
title = {{Coupled dictionary training for image super-resolution}},
volume = {21},
year = {2012}
}
@article{Freeman2002,
abstract = {We call methods for achieving high-resolution enlargements of
pixel-based images super-resolution algorithms. Many applications in
graphics or image processing could benefit from such resolution
independence, including image-based rendering (IBR), texture mapping,
enlarging consumer photographs, and converting NTSC video content to
high-definition television. We built on another training-based
super-resolution algorithm and developed a faster and simpler algorithm
for one-pass super-resolution. Our algorithm requires only a
nearest-neighbor search in the training set for a vector derived from
each patch of local image data. This one-pass super-resolution algorithm
is a step toward achieving resolution independence in image-based
representations. We don't expect perfect resolution independence-even
the polygon representation doesn't have that-but increasing the
resolution independence of pixel-based representations is an important
task for IBR},
author = {Freeman, William T. and Jones, Thouis R. and Pasztor, Egon C.},
doi = {10.1109/38.988747},
isbn = {0-7695-0164-8},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
number = {2},
pages = {56--65},
pmid = {20616400},
title = {{Example-based super-resolution}},
volume = {22},
year = {2002}
}
@article{Zhang2010,
abstract = {In many surveillance video applications, it is of interest to recognize a region of interest (ROI), which often occupies a small portion of a low-resolution, noisy video. This paper proposes an edge-preserving maximum a posteriori (MAP) estimation based super-resolution algorithm using a weighted directional Markov image prior model for a ROI from more than one low-resolution surveillance image. Conjugate gradient (CG) optimization based on standard operations on images is then developed to improve the computational efficiency of the algorithm. The proposed algorithm is tested on different series of surveillance images. The experimental results indicate that the proposed algorithm has considerable effectiveness in terms of both objective measurements and visual evaluation. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Zhang, Liangpei and Zhang, Hongyan and Shen, Huanfeng and Li, Pingxiang},
doi = {10.1016/j.sigpro.2009.09.002},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Signal Processing/2010\_A super-resolution reconstruction algorithm for surveillance images.pdf:pdf},
isbn = {0165-1684},
issn = {01651684},
journal = {Signal Processing},
keywords = {CG,MAP,Super-resolution,Surveillance images},
number = {3},
pages = {848--859},
publisher = {Elsevier},
title = {{A super-resolution reconstruction algorithm for surveillance images}},
url = {http://dx.doi.org/10.1016/j.sigpro.2009.09.002},
volume = {90},
year = {2010}
}
@article{Tai2012,
author = {Tai, Shen-Chuan and Kuo, Tse-Ming and Iao, Chon-Hong and Liao, Tzu-Wen},
doi = {10.1109/IS3C.2012.182},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/2012 International Symposium on Computer, Consumer and Control/2012\_A Fast Algorithm for Single Image Super Resolution in Both Wavelet and Spatial Domain.pdf:pdf},
isbn = {978-1-4673-0767-3},
journal = {2012 International Symposium on Computer, Consumer and Control},
keywords = {-super resolution,edge refinement,projection,scan lines,wavelet},
pages = {702--705},
title = {{A Fast Algorithm for Single Image Super Resolution in Both Wavelet and Spatial Domain}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6228405},
year = {2012}
}
@article{Ishizaka2013,
author = {Ishizaka, K. and Miyamoto, T. and Akimoto, S. and Iketani, a. and Hosomi, T. and Sakai, J.},
doi = {10.1109/CoolChips.2013.6547918},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Symposium on Low-Power and High-Speed Chips - Proceedings for 2013 COOL Chips XVI/2013\_Power efficient realtime super resolution by virtual pipeline technique on a server with manycore coprocessors.pdf:pdf},
isbn = {9781467357814},
journal = {IEEE Symposium on Low-Power and High-Speed Chips - Proceedings for 2013 COOL Chips XVI},
keywords = {Coprocessor,Manycore,Power Efficiency,Super Resolution},
pages = {2--4},
title = {{Power efficient realtime super resolution by virtual pipeline technique on a server with manycore coprocessors}},
volume = {2},
year = {2013}
}
@article{Ram2014,
author = {Ram, Sundaresh and Rodriguez, Jeffrey J},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2014\_Single Image Super-Resolution Using Dictionary-Based Local Regression.pdf:pdf},
isbn = {9781479940530},
pages = {121--124},
title = {{Single Image Super-Resolution Using Dictionary-Based Local Regression}},
year = {2014}
}
@article{Lin2013,
author = {Lin, Wun-Ting and Lai, Shang-Hong},
doi = {10.1109/ACPR.2013.107},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/2013 2nd IAPR Asian Conference on Pattern Recognition/2013\_Single Image Super-Resolution Based on Local Self-Similarity.pdf:pdf},
isbn = {978-1-4799-2190-4},
journal = {2013 2nd IAPR Asian Conference on Pattern Recognition},
keywords = {-single-image super-resolution,blur kernel and reconstructing,local self-similarity,ously estimating the critical,reconstruction-based super-resolution,the high-resolution images,with the gradually maturing},
pages = {191--195},
title = {{Single Image Super-Resolution Based on Local Self-Similarity}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6778308},
year = {2013}
}
@article{Alamalence,
author = {Alamalence, Inc.},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/Unknown\_Superresolution Algorithms Test.pdf:pdf},
title = {{Superresolution Algorithms Test}}
}
@article{Zhang2013,
author = {Zhang, Di and Du, Minghui},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2013\_Super-Resolution Image Reconstruction via Adaptive Sparse Representation and Joint Dictionary Training.pdf:pdf},
isbn = {9781479927647},
keywords = {-super-resolution},
number = {2012},
pages = {516--521},
title = {{Super-Resolution Image Reconstruction via Adaptive Sparse Representation and Joint Dictionary Training}},
year = {2013}
}
@article{Krichane2006,
author = {Krichane, Karim},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2006\_Super Resolution Project Developer ’ s Guide.pdf:pdf},
pages = {1--5},
title = {{Super Resolution Project Developer ’ s Guide}},
year = {2006}
}
@article{Gao2012,
abstract = {The neighbor-embedding (NE) algorithm for single-image super-resolution (SR) reconstruction assumes that the feature spaces of low-resolution (LR) and high-resolution (HR) patches are locally isometric. However, this is not true for SR because of one-to-many mappings between LR and HR patches. To overcome or at least to reduce the problem for NE-based SR reconstruction, we apply a joint learning technique to train two projection matrices simultaneously and to map the original LR and HR feature spaces onto a unified feature subspace. Subsequently, the k -nearest neighbor selection of the input LR image patches is conducted in the unified feature subspace to estimate the reconstruction weights. To handle a large number of samples, joint learning locally exploits a coupled constraint by linking the LR-HR counterparts together with the K-nearest grouping patch pairs. In order to refine further the initial SR estimate, we impose a global reconstruction constraint on the SR outcome based on the maximum a posteriori framework. Preliminary experiments suggest that the proposed algorithm outperforms NE-related baselines.},
author = {Gao, Xinbo and Zhang, Kaibing and Tao, Dacheng and Li, Xuelong},
doi = {10.1109/TIP.2011.2161482},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2012\_Joint learning for single-image super-resolution via a coupled constraint.pdf:pdf},
isbn = {1057-7149},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Grouping patch pairs (GPPs),joint learning,neighbor embedding (NE),super-resolution (SR)},
number = {2},
pages = {469--480},
pmid = {22262669},
title = {{Joint learning for single-image super-resolution via a coupled constraint}},
volume = {21},
year = {2012}
}
@article{Vishnukumar2014,
abstract = {Super-resolution is a widely used technique to increase the resolution of an image by algorithmic methods. Super-resolution from a single image is required in many real world applications. But it is a challenging task to preserve the local edge structures and visual quality in single image super-resolution. Conventional as well as advanced methods maintain the quantitative measures, but most of the times they fail to preserve edges and visual quality. We propose here a single image super-resolution algorithm which preserves the edges and at the same time maintains the visual quality, in a relatively better way. In this method, self-examples are created from a high frequency layer which is formed by performing the difference operation between the given low-resolution image and down-scaled and subsequently up-scaled version of the low-resolution image. The proposed method computes the root mean square difference of features extracted from high frequency layers of low-resolution, interpolated high-resolution and partially reconstructed high-resolution images. These difference values are fed into a Gaussian function to compute the weights which are subsequently used to perform the weighted average. The experimental analysis proves the ability of the method in improving the visual quality as well as in preserving edge information. ?? 2014 Elsevier B.V.},
author = {Vishnukumar, S. and Nair, Madhu S. and Wilscy, M.},
doi = {10.1016/j.sigpro.2014.05.033},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Signal Processing/2014\_Edge preserving single image super-resolution with improved visual quality.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Edge preserving,Self-example based,Single image,Super-resolution},
pages = {283--297},
title = {{Edge preserving single image super-resolution with improved visual quality}},
volume = {105},
year = {2014}
}
@inproceedings{Shen2014,
abstract = {Super resolution is a process to generate high-resolution images from their low-resolution versions. In many applications such as super-HD (4K) TV, super resolution has to be performed in real time. In this paper we propose a real-time image/video super-resolution algorithm, which achieves good performance at low computational cost via off-line learning of interpolation errors in different pixel contexts. The proposed algorithm consists of three stages: fast edge-guided interpolation to generate an initial HR estimation, GPU-aided de-convolution, and error feedback compensation. All three stages can be implemented with GPU to support real-time applications. Experiments demonstrate the competitive performance of the new real-time super-resolution algorithm in both PSNR and visual quality.},
author = {Shen, Yuxiang and Wu, Xiaolin and Deng, Xiaowei},
booktitle = {2014 IEEE Visual Communications and Image Processing Conference},
doi = {10.1109/VCIP.2014.7051560},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/2014 IEEE Visual Communications and Image Processing Conference/2014\_GPU-aided real-time imagevideo super resolution based on error feedback.pdf:pdf},
isbn = {978-1-4799-6139-9},
keywords = {GPU-aided deconvolution,GPU-aided real-time image-video super resolution a,Graphics processing units,Image edge detection,Image resolution,Interpolation,PSNR,Real-time systems,Signal resolution,Streaming media,Super resolution,artificial neural network,error compensation,error feedback,error feedback compensation,fast edge-guided interpolation,graphics processing units,high-resolution image generation,image resolution,initial HR estimation,interpolation,interpolation errors,learning (artificial intelligence),low computational cost,machine learning,off-line learning,parallel computing,pixel contexts,super-HD TV,video signal processing,visual quality},
month = dec,
pages = {286--290},
publisher = {IEEE},
shorttitle = {Visual Communications and Image Processing Confere},
title = {{GPU-aided real-time image/video super resolution based on error feedback}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7051560},
year = {2014}
}
@article{Farsiu2004,
abstract = {Super-Resolution reconstruction produces one or a set of high-resolution images from a sequence of low-resolution frames. This article reviews a variety of Super-Resolution methods proposed in the last 20 years, and provides some insight into, and a summary of, our recent contributions to the general Super-Resolution problem. In the process, a detailed study of several very important aspects of Super-Resolution, often ignored in the literature, is presented. Specifically, we discuss robustness, treatment of color, and dynamic operation modes. Novel methods for addressing these issues are accompanied by experimental results on simulated and real data. Finally, some future challenges in Super-Resolution are outlined and discussed. 2004 Wiley Periodicals, Inc. Int J Imaging Syst Technol 14, 47-57, 2004; Published online in Wiley InterScience DOI 10.1002/ima.20007},
author = {Farsiu, Sina and Robinson, Dirk and Elad, Michael and Milanfar, Peyman},
doi = {10.1002/ima.20007},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/International Journal of Imaging Systems and Technology/2004\_Advances and challenges in super-resolution.pdf:pdf},
isbn = {0899-9457},
issn = {08999457},
journal = {International Journal of Imaging Systems and Technology},
keywords = {Demosaicing,Dynamic Super-Resolution,Image-reconstruction,Inverse problem,Robust estimation,Robust regularization,Super-Resolution},
number = {2},
pages = {47--57},
pmid = {20031399},
title = {{Advances and challenges in super-resolution}},
volume = {14},
year = {2004}
}
@article{Yue2014,
abstract = {In this paper, we present a locally adaptive regularized super-resolution model for images with mixed noise and outliers. The proposed method adaptively assigns the local norms in the data fidelity term of the regularized model. Specifically, it determines different norm values for different pixel locations, according to the impulse noise and motion outlier detection results. The L 1 norm is employed for pixels with impulse noise and motion outliers, and the L2 norm is used for the other pixels. In order to balance the difference in the constraint strength between the L1 norm and the L2 norm, a strategy to adaptively estimate a weighted parameter is put forward. The experimental results confirm the superiority of the proposed method for different images with mixed noise and outliers. © 2014 Elsevier B.V.},
author = {Yue, Linwei and Shen, Huanfeng and Yuan, Qiangqiang and Zhang, Liangpei},
doi = {10.1016/j.sigpro.2014.04.031},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Signal Processing/2014\_A locally adaptive L1-L2 norm for multi-frame super-resolution of images with mixed noise and outliers.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Adaptive norm,Adaptive weight estimation,Mixed noise,Motion outliers,Super-resolution},
pages = {156--174},
publisher = {Elsevier},
title = {{A locally adaptive L1-L2 norm for multi-frame super-resolution of images with mixed noise and outliers}},
url = {http://dx.doi.org/10.1016/j.sigpro.2014.04.031},
volume = {105},
year = {2014}
}
@article{Hore2010,
abstract = {In this paper, we analyse two well-known objective image quality metrics, the peak-signal-to-noise ratio (PSNR) as well as the structural similarity index measure (SSIM), and we derive a simple mathematical relationship between them which works for various kinds of image degradations such as Gaussian blur, additive Gaussian white noise, jpeg and jpeg2000 compression. A series of tests realized on images extracted from the Kodak database gives a better understanding of the similarity and difference between the SSIM and the PSNR.},
author = {Hor\'{e}, Alain and Ziou, Djemel},
doi = {10.1109/ICPR.2010.579},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings - International Conference on Pattern Recognition/2010\_Image quality metrics PSNR vs. SSIM.pdf:pdf},
isbn = {9780769541099},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
keywords = {Image quality metrics,PSNR,SSIM},
pages = {2366--2369},
pmid = {5596999},
title = {{Image quality metrics: PSNR vs. SSIM}},
year = {2010}
}
@article{Sun2008,
abstract = {In this paper, we propose an image super-resolution approach using a novel generic image prior - gradient profile prior, which is a parametric prior describing the shape and the sharpness of the image gradients. Using the gradient profile prior learned from a large number of natural images, we can provide a constraint on image gradients when we estimate a hi-resolution image from a low-resolution image. With this simple but very effective prior, we are able to produce state-of-the-art results. The reconstructed hi-resolution image is sharp while has rare ringing or jaggy artifacts.},
author = {Sun, Jian and Sun, Jian and Xu, Zongben and Shum, Heung Yeung},
doi = {10.1109/CVPR.2008.4587659},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR/2008\_Image super-resolution using gradient profile prior.pdf:pdf},
isbn = {9781424422432},
issn = {1063-6919},
journal = {26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR},
title = {{Image super-resolution using gradient profile prior}},
year = {2008}
}
@article{Yang2013,
abstract = {We propose a fast regression model for practical single image $\backslash$nsuper-resolution based on in-place examples, by leveraging two fundamental $\backslash$nsuper-resolution approaches- learning from an external database and learning $\backslash$nfrom self-examples. Our in-place self-similarity refines the recently proposed $\backslash$nlocal self-similarity by proving that a patch in the upper scale image have good $\backslash$nmatches around its origin location in the lower scale image. Based on the $\backslash$nin-place examples, a first-order approximation of the nonlinear mapping function $\backslash$nfrom low-to high-resolution image patches is learned. Extensive experiments on $\backslash$nbenchmark and real-world images demonstrate that our algorithm can produce $\backslash$nnatural-looking results with sharp edges and preserved fine details, while the $\backslash$ncurrent state-of-the-art algorithms are prone to visual artifacts. Furthermore, $\backslash$nour model can easily extend to deal with noise by combining the regression $\backslash$nresults on multiple in-place examples for robust estimation. The algorithm runs $\backslash$nfast and is particularly useful for practical applications, where the input $\backslash$nimages typically contain diverse textures and they are potentially contaminated $\backslash$nby noise or compression artifacts.},
author = {Yang, Jianchao and Lin, Zhe and Cohen, Scott},
doi = {10.1109/CVPR.2013.141},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition/2013\_Fast image super-resolution based on in-place example regression.pdf:pdf},
isbn = {978-0-7695-4989-7},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer  Vision and Pattern Recognition},
keywords = {image restoration,image upscaling,in-place matching,self-example,self-similarity,super-resolution},
pages = {1059--1066},
title = {{Fast image super-resolution based on in-place example regression}},
year = {2013}
}
@incollection{Yang2010a,
author = {Yang, Jianchao and Huang, Thomas},
booktitle = {Super-resolution imaging},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Super-resolution imaging/2010\_Image super-resolution Historical overview and future challenges.pdf:pdf},
isbn = {1439819319},
pages = {3--25},
title = {{Image super-resolution: Historical overview and future challenges}},
url = {http://books.google.com/books?hl=en\&lr=\&id=fjTUbMnvOkgC\&oi=fnd\&pg=PA1\&dq=Image+super-resolution:+Historical+overview+and+future+challenges\&ots=53GZConOGy\&sig=oHgGJVo\_57Tv19cxLV\_XMtC1OPw},
year = {2010}
}
@article{,
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/Unknown\_EDGE PRESERVING SINGLE IMAGE SUPER RESOLUTION IN SPARSE ENVIRONMENT Srimanta Mandal and Anil Kumar Sao School of Computing and E.pdf:pdf},
number = {1},
pages = {1--5},
title = {{EDGE PRESERVING SINGLE IMAGE SUPER RESOLUTION IN SPARSE ENVIRONMENT Srimanta Mandal and Anil Kumar Sao School of Computing and Electrical Engineering Indian Institute of Technology Mandi , India}}
}
@article{Helstrom1967,
abstract = {The restoration of optical images, as well as the unfolding of spectroscopic and other data that have been convolved with a window function or an instrumental impulse response, can be viewed as the solution of an integral equation. Solution of such an integral equation when the data are corrupted by noise or experimental error is treated as the problem of finding an estimate that is a linear functional of the data and minimizes the mean squared error between the true solution and itself. The estimate depends on assumptions about the spectral densities of the images and the noise, the choice of which is discussed. Coherent optical processing and digital processing are described.},
author = {Helstrom, Carl W.},
doi = {10.1364/JOSA.57.000297},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Journal of the Optical Society of America/1967\_Image Restoration by the Method of Least Squares.pdf:pdf},
issn = {0030-3941},
journal = {Journal of the Optical Society of America},
number = {3},
pages = {297},
title = {{Image Restoration by the Method of Least Squares}},
volume = {57},
year = {1967}
}
@article{Bevilacqua2012,
author = {Bevilacqua, Marco and Roumy, Aline and Guillemot, Christine and Morel, Marie-line Alberi},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2012\_LOW-COMPLEXITY SINGLE-IMAGE SUPER-RESOLUTION BASED ON NONNEGATIVE NEIGHBOR EMBEDDING.pdf:pdf},
title = {{LOW-COMPLEXITY SINGLE-IMAGE SUPER-RESOLUTION BASED ON NONNEGATIVE NEIGHBOR EMBEDDING}},
year = {2012}
}
@article{Zeyde2012,
abstract = {This paper deals with the single image scale-up problem us- ing sparse-representation modeling. The goal is to recover an original image from its blurred and down-scaled noisy version. Since this problem is highly ill-posed, a prior is needed in order to regularize it. The liter- ature offers various ways to address this problem, ranging from simple linear space-invariant interpolation schemes (e.g., bicubic interpolation), to spatially-adaptive and non-linear filters of various sorts. We embark from a recently-proposed successful algorithm by Yang et. al. [13,14], and similarly assume a local Sparse-Land model on image patches, serving as regularization. Several important modifications to the above-mentioned solution are introduced, and are shown to lead to improved results. These modifications include a major simplification of the overall process both in terms of the computational complexity and the algorithm architecture, using a different training approach for the dictionary-pair, and introducing the ability to operate without a training- set by boot-strapping the scale-up task from the given low-resolution image. We demonstrate the results on true images, showing both visual and PSNR improvements.},
author = {Zeyde, Roman and Elad, Michael and Protter, Matan},
doi = {10.1007/978-3-642-27413-8\_47},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)/2012\_On single image scale-up using sparse-representations.pdf:pdf},
isbn = {9783642274121},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {1},
pages = {711--730},
title = {{On single image scale-up using sparse-representations}},
volume = {6920 LNCS},
year = {2012}
}
@article{Chang2004,
abstract = { In this paper, we propose a novel method for solving single-image super-resolution problems. Given a low-resolution image as input, we recover its high-resolution counterpart using a set of training examples. While this formulation resembles other learning-based methods for super-resolution, our method has been inspired by recent manifold teaming methods, particularly locally linear embedding (LLE). Specifically, small image patches in the lowand high-resolution images form manifolds with similar local geometry in two distinct feature spaces. As in LLE, local geometry is characterized by how a feature vector corresponding to a patch can be reconstructed by its neighbors in the feature space. Besides using the training image pairs to estimate the high-resolution embedding, we also enforce local compatibility and smoothness constraints between patches in the target high-resolution image through overlapping. Experiments show that our method is very flexible and gives good empirical results.},
author = {Chang, Hong Chang Hong and Yeung, Dit-Yan Yeung Dit-Yan and Xiong, Yimin Xiong Yimin},
doi = {10.1109/CVPR.2004.1315043},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004/2004\_Super-resolution through neighbor embedding.pdf:pdf},
isbn = {0-7695-2158-4},
issn = {1063-6919},
journal = {Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
title = {{Super-resolution through neighbor embedding}},
volume = {1},
year = {2004}
}
@article{Timofte2013a,
abstract = {Recently there have been significant advances in image up scaling or $\backslash$nimage super-resolution based on a dictionary of low and high resolution $\backslash$nexemplars. The running time of the methods is often ignored despite the fact $\backslash$nthat it is a critical factor for real applications. This paper proposes fast $\backslash$nsuper-resolution methods while making no compromise on quality. First, we $\backslash$nsupport the use of sparse learned dictionaries in combination with neighbor $\backslash$nembedding methods. In this case, the nearest neighbors are computed using the $\backslash$ncorrelation with the dictionary atoms rather than the Euclidean distance. $\backslash$nMoreover, we show that most of the current approaches reach top performance for $\backslash$nthe right parameters. Second, we show that using global collaborative coding has $\backslash$nconsiderable speed advantages, reducing the super-resolution mapping to a $\backslash$nprecomputed projective matrix. Third, we propose the anchored neighborhood $\backslash$nregression. That is to anchor the neighborhood embedding of a low resolution $\backslash$npatch to the nearest atom in the dictionary and to precompute the corresponding $\backslash$nembedding matrix. These proposals are contrasted with current state-of-the-art $\backslash$nmethods on standard images. We obtain similar or improved quality and one or two $\backslash$norders of magnitude speed improvements.},
author = {Timofte, R and De, V and {Van Gool}, L},
doi = {10.1109/ICCV.2013.241},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Computer Vision (ICCV), 2013 IEEE International Conference on/2013\_Anchored Neighborhood Regression for Fast Example-Based Super-Resolution.pdf:pdf},
isbn = {978-1-4799-2840-8},
issn = {1550-5499},
journal = {Computer Vision (ICCV), 2013 IEEE International Conference on},
keywords = {image coding;image reconstruction;image resolution},
pages = {1920--1927},
title = {{Anchored Neighborhood Regression for Fast Example-Based Super-Resolution}},
year = {2013}
}
@article{Zhang2011,
author = {Zhang, Haichao and Yang, Jianchao and Zhang, Yanning and Huang, Thomas S},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2011\_SPARSE REPRESENTATION BASED BLIND IMAGE DEBLURRING School of Computer Science , Northwestern Polytechnical University , Xi ’ an , C.pdf:pdf},
isbn = {9781612843506},
pages = {1353--1356},
title = {{SPARSE REPRESENTATION BASED BLIND IMAGE DEBLURRING School of Computer Science , Northwestern Polytechnical University , Xi ’ an , China 710129 Beckman Institute , University of Illinois at Urbana-Champaign , IL , USA 61801}},
year = {2011}
}
@article{Yang2010,
abstract = {This paper presents a new approach to single-image superresolution, based upon sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low-resolution and high-resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low-resolution image patch can be applied with the high-resolution image patch dictionary to generate a high-resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs , reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super-resolution (SR) and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle SR with noisy inputs in a more unified framework.},
author = {Yang, Jianchao and Wright, J. and Huang, T.S. and Ma, Yi},
doi = {10.1109/TIP.2010.2050625},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2010\_Image Super-Resolution Via Sparse Representation.pdf:pdf},
isbn = {1057-7149 VO  - 19},
issn = {1057-7149},
journal = {IEEE Transactions on Image Processing},
number = {11},
pages = {2861--2873},
pmid = {20483687},
title = {{Image Super-Resolution Via Sparse Representation}},
url = {http://ieeexplore.ieee.org/ielx5/83/5602158/05466111.pdf?tp=\&arnumber=5466111\&isnumber=5602158$\backslash$nhttp://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5466111},
volume = {19},
year = {2010}
}
@article{Bevilacqua2012,
abstract = {This paper describes a single-image super-resolution (SR) algorithm based on non- negative neighbor embedding. It belongs to the family of single-image example-based SR algorithms, since it uses a dictionary of low resolution (LR) and high resolution (HR) trained patch pairs to infer the unknown HR details. Each LR feature vector in the input image is expressed as the weighted combination of its K nearest neighbors in the dictio- nary; the corresponding HR feature vector is reconstructed under the assumption that the local LR embedding is preserved. Three key aspects are introduced in order to build a low-complexity competitive algorithm: (i) a compact but efficient representation of the patches (feature representation) (ii) an accurate estimation of the patches by their near- est neighbors (weight computation) (iii) a compact and already built (therefore external) dictionary, which allows a one-step upscaling. The neighbor embedding SR algorithm so designed is shown to give good visual results, comparable to other state-of-the-art methods, while presenting an appreciable reduction of the computational time.},
author = {Bevilacqua, Marco and Roumy, Aline and Guillemot, Christine and Morel, Marie-Line Alberi},
doi = {10.5244/C.26.135},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/British Machine Vision Conference/2012\_Low-Complexity Single-Image Super-Resolution based on Nonnegative Neighbor Embedding.pdf:pdf},
isbn = {1-901725-46-4},
journal = {British Machine Vision Conference},
keywords = {machine learning,patch pairs,single image,super resolution},
number = {Ml},
pages = {1--10},
title = {{Low-Complexity Single-Image Super-Resolution based on Nonnegative Neighbor Embedding}},
year = {2012}
}
@article{Zhang2012,
abstract = {Reconstruction- and example-based super-resolution (SR) methods are promising for restoring a high-resolution (HR) image from low-resolution (LR) image(s). Under large magnification, reconstruction-based methods usually fail to hallucinate visual details while example-based methods sometimes introduce unexpected details. Given a generic LR image, to reconstruct a photo-realistic SR image and to suppress artifacts in the reconstructed SR image, we introduce a multi-scale dictionary to a novel SR method that simultaneously integrates local and non-local priors. The local prior suppresses artifacts by using steering kernel regression to predict the target pixel from a small local area. The non-local prior enriches visual details by taking a weighted average of a large neighborhood as an estimate of the target pixel. Essentially, these two priors are complementary to each other. Experimental results demonstrate that the proposed method can produce high quality SR recovery both quantitatively and perceptually.},
author = {Zhang, Kaibing and Gao, Xinbo and Tao, Dacheng and Li, Xuelong},
doi = {10.1109/CVPR.2012.6247791},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition/2012\_Multi-scale dictionary for single image super-resolution.pdf:pdf},
isbn = {9781467312264},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {1114--1121},
title = {{Multi-scale dictionary for single image super-resolution}},
year = {2012}
}
