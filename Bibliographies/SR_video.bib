@article{Hu2014,
author = {Hu, Jie},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2014\_Real Time Super Resolution Reconstruction for Video Stream based on GPU.pdf:pdf},
isbn = {9781479962846},
number = {20125153025},
pages = {9--12},
title = {{Real Time Super Resolution Reconstruction for Video Stream based on GPU}},
year = {2014}
}
@article{Shen2014,
author = {Shen, Yuxiang and Wu, Xiaolin and Deng, Xiaowei},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/2014 IEEE Visual Communications and Image Processing Conference/2014\_GPU-aided real-time imagevideo super resolution based on error feedback.pdf:pdf},
isbn = {9781479961399},
pages = {286--290},
title = {{GPU-Aided Real-Time Image / Video Super Resolution Based on Error Feedback}},
year = {2014}
}
@article{Chukwu2009,
author = {Chukwu, Michael},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2009\_Video Super Resolution.pdf:pdf},
title = {{Video Super Resolution}},
year = {2009}
}
@article{Takeda2009,
abstract = {The need for precise (subpixel accuracy) motion estimates in conventional super-resolution has limited its applicability to only video sequences with relatively simple motions such as global translational or affine displacements. In this paper, we introduce a novel framework for adaptive enhancement and spatiotemporal upscaling of videos containing complex activities without explicit need for accurate motion estimation. Our approach is based on multidimensional kernel regression, where each pixel in the video sequence is approximated with a 3-D local (Taylor) series, capturing the essential local behavior of its spatiotemporal neighborhood. The coefficients of this series are estimated by solving a local weighted least-squares problem, where the weights are a function of the 3-D space-time orientation in the neighborhood. As this framework is fundamentally based upon the comparison of neighboring pixels in both space and time, it implicitly contains information about the local motion of the pixels across time, therefore rendering unnecessary an explicit computation of motions of modest size. The proposed approach not only significantly widens the applicability of super-resolution methods to a broad variety of video sequences containing complex motions, but also yields improved overall performance. Using several examples, we illustrate that the developed algorithm has super-resolution capabilities that provide improved optical resolution in the output, while being able to work on general input video with essentially arbitrary motion.},
author = {Takeda, Hiroyuki and Milanfar, Peyman and Protter, Matan and Elad, Michael},
doi = {10.1109/TIP.2009.2023703},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2009\_Super-resolution without explicit subpixel motion estimation.pdf:pdf},
isbn = {1057-7149},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Denoising,Frame rate upconversion,Interpolation,Kernel,Local polynomial,Nonlinear filter,Nonparametric,Regression,Spatially adaptive,Super-resolution},
number = {9},
pages = {1958--1975},
pmid = {19473940},
title = {{Super-resolution without explicit subpixel motion estimation}},
volume = {18},
year = {2009}
}
@article{Caner2003,
abstract = { In many surveillance video applications, it is of interest to recognize an object or a person, which occupies a small portion of a low-resolution, noisy video. This paper addresses the problem of super-resolution recovery of a region of interest from more than one low-resolution view of a scene recorded by multiple cameras. The multiple camera scenario alleviates the difficulty in registration of multiple frames of video that contain non-rigid or multiple object motion in the single camera case. With proper temporal registration of multiple videos, arbitrary scene motion can be handled. The success of super-resolution recovery from multiple views in real applications vitally depends on two factors: i) the accuracy of multiple view registration results, and ii) the accuracy of the camera and data acquisition model. We propose a system, which consists of a method for sub-pixel accurate spatio-temporal alignment of multiple video sequences for view registration and the projections onto convex sets method for super-resolution recovery. Experiments were implemented using two commercial analog video cameras, which do not perform on-board compression. Experimental results show that the super resolution recovery of dynamic scenes can be achieved as long as the multiple views of the scene can be registered with sub-pixel accuracy.},
author = {Caner, G. and a.M. Tekalp and Heinzelman, W.},
doi = {10.1109/ICME.2003.1220866},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)/2003\_Super resolution recovery for multi-camera surveillance imaging.pdf:pdf},
isbn = {0-7803-7965-9},
journal = {2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)},
title = {{Super resolution recovery for multi-camera surveillance imaging}},
volume = {1},
year = {2003}
}
@article{Su2012,
abstract = {Super-resolution is a widely applied technique that improves the resolution of input images by software methods. Most conventional reconstruction-based super-resolution algorithms assume accurate dense optical flow fields between the input frames, and their performance degrades rapidly when the motion estimation result is not accurate enough. However, optical flow estimation is usually difficult, particularly when complicated motion is presented in real-world videos. In this paper, we explore a new way to solve this problem by using sparse feature point correspondences between the input images. The feature point correspondences, which are obtained by matching a set of feature points, are usually precise and much more robust than dense optical flow fields. This is because the feature points represent well-selected significant locations in the image, and performing matching on the feature point set is usually very accurate. In order to utilize the sparse correspondences in conventional super-resolution, we extract an adaptive support region with a reliable local flow field from each corresponding feature point pair. The normalized prior is also proposed to increase the visual consistency of the reconstructed result. Extensive experiments on real data were carried out, and results show that the proposed algorithm produces high-resolution images with better quality, particularly in the presence of large-scale or complicated motion fields.},
author = {Su, Heng and Wu, Ying and Zhou, Jie},
doi = {10.1109/TIP.2011.2173204},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2012\_Super-resolution without dense flow.pdf:pdf},
isbn = {1057-7149},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Feature point correspondence,super-resolution reconstruction,support region,total variation (TV) prior},
number = {4},
pages = {1782--1795},
pmid = {22027381},
title = {{Super-resolution without dense flow}},
volume = {21},
year = {2012}
}
@article{Xiong2010,
abstract = {This paper proposes a robust single-image super-resolution method for enlarging low quality web image/video degraded by downsampling and compression. To simultaneously improve the resolution and perceptual quality of such web image/video, we bring forward a practical solution which combines adaptive regularization and learning-based super-resolution. The contribution of this work is twofold. First, we propose to analyze the image energy change characteristics during the iterative regularization process, i.e., the energy change ratio between primitive (e.g., edges, ridges and corners) and nonprimitive fields. Based on the revealed convergence property of the energy change ratio, appropriate regularization strength can then be determined to well balance compression artifacts removal and primitive components preservation. Second, we verify that this adaptive regularization can steadily and greatly improve the pair matching accuracy in learning-based super-resolution. Consequently, their combination effectively eliminates the quantization noise and meanwhile faithfully compensates the missing high-frequency details, yielding robust super-resolution performance in the compression scenario. Experimental results demonstrate that our solution produces visually pleasing enlargements for various web images/videos.},
author = {Xiong, Zhiwei and Sun, Xiaoyan and Wu, Feng},
doi = {10.1109/TIP.2010.2045707},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2010\_Robust web imagevideo super-resolution.pdf:pdf},
isbn = {1941-0042 (Electronic)$\backslash$r1057-7149 (Linking)},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Adaptive regularization,compression artifacts removal,energy change ratio,learning-based super-resolution (SR),primitive/nonprimitive field,web image/video},
number = {8},
pages = {2017--2028},
pmid = {20236889},
title = {{Robust web image/video super-resolution}},
volume = {19},
year = {2010}
}
@article{Wright2010,
abstract = {This paper presents a new approach to single-image super-resolution, based on sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low resolution and high resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low resolution image patch can be applied with the high resolution image patch dictionary to generate a high resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs [1], reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super-resolution and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle super-resolution with noisy inputs in a more unified framework.},
author = {Wright, John and Huang, Thomas and Yang, Jianchao and Ma, Yi},
doi = {10.1109/TIP.2010.2050625},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE transactions on image processing a publication of the IEEE Signal Processing Society/2010\_Image Super-Resolution via Sparse Representation.pdf:pdf},
isbn = {978-1-4244-2242-5},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
pages = {1--13},
pmid = {20483687},
title = {{Image Super-Resolution via Sparse Representation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20483687$\backslash$nhttp://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4587647},
year = {2010}
}
@article{Su2013,
abstract = {In this paper, the learning-based single image super-resolution (SR) is regarded as a problem of space structure learning. We propose a new SR method that identifies a space from the low-resolution (LR) image space that best preserves the structure of the high-resolution (HR) image space. The inference between the two structure-consistent spaces proves to be accurate and predicts HR image patches with higher quality. An effective iterative algorithm is also proposed to find the near-optimal solution to the model, which can be easily implemented in parallel computing. Extensive experiments are performed to show the effectiveness of the proposed algorithm. © 2013 Published by Elsevier B.V.},
author = {Su, Heng and Jiang, Nan and Wu, Ying and Zhou, Jie},
doi = {10.1016/j.patrec.2013.07.012},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Pattern Recognition Letters/2013\_Single image super-resolution based on space structure learning.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Metric learning,Single image super-resolution,Space structure learning},
number = {16},
pages = {2094--2101},
publisher = {Elsevier B.V.},
title = {{Single image super-resolution based on space structure learning}},
url = {http://dx.doi.org/10.1016/j.patrec.2013.07.012},
volume = {34},
year = {2013}
}
@article{Lopez2009,
author = {Lopez, Sebastian and Callico, Gustavo M and Tobajas, Felix and Lopez, Jose F and Sarmiento, Roberto},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2009\_A Novel Real-Time DSP-Based Video Super-Resolution System.pdf:pdf},
number = {4},
pages = {2264--2270},
title = {{A Novel Real-Time DSP-Based Video Super-Resolution System}},
volume = {55},
year = {2009}
}
@article{Cheng2013,
abstract = {In this study, a classification-based video super-resolution method using artificial neural network (ANN) is proposed to enhance low-resolution (LR) to high-resolution (HR) frames. The proposed method consists of four main steps: classification, motion-trace volume collection, temporal adjustment, and ANN prediction. A classifier is designed based on the edge properties of a pixel in the LR frame to identify the spatial information. To exploit the spatio-temporal information, a motion-trace volume is collected using motion estimation, which can eliminate unfathomable object motion in the LR frames. In addition, temporal lateral process is employed for volume adjustment to reduce unnecessary temporal features. Finally, ANN is applied to each class to learn the complicated spatio-temporal relationship between LR and HR frames. Simulation results show that the proposed method successfully improves both peak signal-to-noise ratio and perceptual quality. © 2013 Elsevier B.V. All rights reserved.},
author = {Cheng, Ming Hui and Hwang, Kao Shing and Jeng, Jyh Horng and Lin, Nai Wei},
doi = {10.1016/j.sigpro.2013.02.013},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Signal Processing/2013\_Classification-based video super-resolution using artificial neural networks.pdf:pdf},
issn = {01651684},
journal = {Signal Processing},
keywords = {Artificial neural network (ANN),Bilateral filter,Classification,Motion estimation,Super-resolution},
number = {9},
pages = {2612--2625},
publisher = {Elsevier},
title = {{Classification-based video super-resolution using artificial neural networks}},
url = {http://dx.doi.org/10.1016/j.sigpro.2013.02.013},
volume = {93},
year = {2013}
}
@article{Li2012,
abstract = {Blind image deblurring, aiming at obtaining the sharp image fromblurred one, is a widely existing prob- lem in image processing. Traditional image deblur- ring methods always use the deconvolution method to remove the blur kernel’s effect, however, deconvolu- tion is so sensitive to noise that inevitable artifacts al- ways exist in the deblurring results, even though regu- larity terms are introduced as constraints. In this pa- per, we propose a novel blind image deblurring method based on the sparse prior of dictionary pair, estimat- ing the sparse coefficient, sharp image and blur ker- nel alternately. The proposed method could avoid the deconvolution problem which is an ill-posed problem, and obtain the result with fewer artifacts. Compared with the state-of-the-art method, experimental results demonstrate that the proposedmethod could obtain bet- ter performance.},
author = {Li, Haisen and Zhang, Yanning},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/International Conference on Pattern Recognition/2012\_Blind Image Deblurring Based on Sparse Prior of Dictionary Pair.pdf:pdf},
isbn = {9784990644116},
issn = {10514651},
journal = {International Conference on Pattern Recognition},
keywords = {Enhancement, Restoration and Filtering,Image and Video Processing,Statistical, Syntactic and Structural Pattern Reco},
number = {Icpr},
pages = {3054--3057},
title = {{Blind Image Deblurring Based on Sparse Prior of Dictionary Pair}},
year = {2012}
}
@article{Cho2009,
abstract = {This paper presents a fast deblurring method that produces a deblur- ring result from a single image of moderate size in a few seconds. We accelerate both latent image estimation and kernel estimation in an iterative deblurring process by introducing a novel prediction step and working with image derivatives rather than pixel values. In the prediction step, we use simple image processing techniques to predict strong edges from an estimated latent image, which will be solely used for kernel estimation. With this approach, a compu- tationally efficient Gaussian prior becomes sufficient for deconvo- lution to estimate the latent image, as small deconvolution artifacts can be suppressed in the prediction. For kernel estimation, we for- mulate the optimization function using image derivatives, and ac- celerate the numerical process by reducing the number of Fourier transforms needed for a conjugate gradient method. We also show that the formulation results in a smaller condition number of the nu- merical system than the use of pixel values, which gives faster con- vergence. Experimental results demonstrate that our method runs an order of magnitude faster than previous work, while the deblur- ring quality is comparable. GPU implementation facilitates further speed-up, making our method fast enough for practical use.},
author = {Cho, Sunghyun and Lee, Seungyong},
doi = {10.1145/1618452.1618491},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/ACM Transactions on Graphics/2009\_Fast motion deblurring.pdf:pdf},
isbn = {0730-0301},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {deblurring,image restoration,motion blur},
number = {5},
pages = {1},
title = {{Fast motion deblurring}},
volume = {28},
year = {2009}
}
@article{He2011,
abstract = {In this paper we address the problem of producing a high-resolution image from a single low-resolution image without any external training set. We propose a framework for both magnification and deblurring using only the original low-resolution image and its blurred version. In our method, each pixel is predicted by its neighbors through the Gaussian process regression. We show that when using a proper covariance function, the Gaussian process regression can perform soft clustering of pixels based on their local structures. We further demonstrate that our algorithm can extract adequate information contained in a single low-resolution image to generate a high-resolution image with sharp edges, which is comparable to or even superior in quality to the performance of other edge-directed and example-based super-resolution algorithms. Experimental results also show that our approach maintains high-quality performance at large magnifications.},
author = {He, He and Siu, Wan-Chi},
doi = {10.1109/CVPR.2011.5995713},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Cvpr 2011/2011\_Single image super-resolution using Gaussian process regression.pdf:pdf},
isbn = {978-1-4577-0393-5},
issn = {1063-6919},
journal = {Cvpr 2011},
pages = {449--456},
title = {{Single image super-resolution using Gaussian process regression}},
year = {2011}
}
@article{,
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Image (Rochester, N.Y.)/2012\_SINGLE IMAGE SUPER-RESOLUTION USING ITERATIVE WIENER FILTER Kwok-Wai Hung and Wan-Chi Siu Department of Electronic and Information.pdf:pdf},
isbn = {9781467300469},
journal = {Image (Rochester, N.Y.)},
number = {3},
pages = {1269--1272},
title = {{SINGLE IMAGE SUPER-RESOLUTION USING ITERATIVE WIENER FILTER Kwok-Wai Hung and Wan-Chi Siu Department of Electronic and Information Engineering The Hong Kong Polytechnic University}},
year = {2012}
}
@article{Su2010,
abstract = {Super-resolution technology provides an effective way to increase image resolution by incorporating additional information from successive input images or training samples. Various super-resolution algorithms have been proposed based on different assumptions, and their relative performances can differ in regions of different characteristics within a single image. Based on this observation, an adaptive algorithm is proposed in this paper to integrate a higher-level image classification task and a lower-level super-resolution process, in which we incorporate reconstruction-based super-resolution algorithms, single image enhancement and image/video classification into a single comprehensive framework. The target high resolution image plane is divided into adaptive-sized blocks and different suitable super-resolution algorithms are automatically selected for the blocks. Then a de-blocking process is applied to reduce block edge artifacts. A new benchmark is also utilized to measure the performance of super-resolution algorithms. Experimental results with real-life videos indicate encouraging improvements with our method.},
author = {Su, Heng and Tang, Liang and Wu, Ying and Member, Senior and Tretter, Daniel and Zhou, Jie and Member, Senior},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2010\_Spatially Adaptive Block-based Super-resolution.pdf:pdf},
journal = {IEEE Transactions on Image Processing},
keywords = {Super-resolution,block based,motion registration error,spatially adaptive framework,super-resolution benchmark},
number = {X},
pages = {1--15},
title = {{Spatially Adaptive Block-based Super-resolution}},
volume = {X},
year = {2010}
}
@article{Dong2014,
archivePrefix = {arXiv},
arxivId = {1501.00092},
author = {Dong, Chao and Loy, Chen Change and He, Kaiming},
eprint = {1501.00092},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/arXiv preprint/2014\_Image Super-Resolution Using Deep Convolutional Networks.pdf:pdf},
journal = {arXiv preprint},
pages = {1--14},
title = {{Image Super-Resolution Using Deep Convolutional Networks}},
year = {2014}
}
@article{Dong2011,
abstract = {As a powerful statistical image modeling technique, sparse representation has been successfully used in various image restoration applications. The success of sparse representation owes to the development of the l(1)-norm optimization techniques and the fact that natural images are intrinsically sparse in some domains. The image restoration quality largely depends on whether the employed sparse domain can represent well the underlying image. Considering that the contents can vary significantly across different images or different patches in a single image, we propose to learn various sets of bases from a precollected dataset of example image patches, and then, for a given patch to be processed, one set of bases are adaptively selected to characterize the local sparse domain. We further introduce two adaptive regularization terms into the sparse representation framework. First, a set of autoregressive (AR) models are learned from the dataset of example image patches. The best fitted AR models to a given patch are adaptively selected to regularize the image local structures. Second, the image nonlocal self-similarity is introduced as another regularization term. In addition, the sparsity regularization parameter is adaptively estimated for better image restoration performance. Extensive experiments on image deblurring and super-resolution validate that by using adaptive sparse domain selection and adaptive regularization, the proposed method achieves much better results than many state-of-the-art algorithms in terms of both PSNR and visual perception.},
archivePrefix = {arXiv},
arxivId = {1012.1184},
author = {Dong, Weisheng and Zhang, Lei and Shi, Guangming and Wu, Xiaolin},
doi = {10.1109/TIP.2011.2108306},
eprint = {1012.1184},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2011\_Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization.pdf:pdf},
isbn = {1057-7149},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Deblurring,image restoration (IR),regularization,sparse representation,super-resolution},
number = {7},
pages = {1838--1857},
pmid = {21278019},
title = {{Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization}},
volume = {20},
year = {2011}
}
@article{Hardie2007,
abstract = {A computationally simple super-resolution algorithm using a type of adaptive Wiener filter is proposed. The algorithm produces an improved resolution image from a sequence of low-resolution (LR) video frames with overlapping field of view. The algorithm uses subpixel registration to position each LR pixel value on a common spatial grid that is referenced to the average position of the input frames. The positions of the LR pixels are not quantized to a finite grid as with some previous techniques. The output high-resolution (HR) pixels are obtained using a weighted sum of LR pixels in a local moving window. Using a statistical model, the weights for each HR pixel are designed to minimize the mean squared error and they depend on the relative positions of the surrounding LR pixels. Thus, these weights adapt spatially and temporally to changing distributions of LR pixels due to varying motion. Both a global and spatially varying statistical model are considered here. Since the weights adapt with distribution of LR pixels, it is quite robust and will not become unstable when an unfavorable distribution of LR pixels is observed. For translational motion, the algorithm has a low computational complexity and may be readily suitable for real-time and/or near real-time processing applications. With other motion models, the computational complexity goes up significantly. However, regardless of the motion model, the algorithm lends itself to parallel implementation. The efficacy of the proposed algorithm is demonstrated here in a number of experimental results using simulated and real video sequences. A computational analysis is also presented.},
author = {Hardie, Russell},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE transactions on image processing a publication of the IEEE Signal Processing Society/2007\_A fast image super-resolution algorithm using an adaptive Wiener filter.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
number = {12},
pages = {2953--2964},
pmid = {18092595},
title = {{A fast image super-resolution algorithm using an adaptive Wiener filter.}},
volume = {16},
year = {2007}
}
@article{Liu2014,
abstract = {Although multiframe super resolution has been extensively studied in past decades, super resolving real-world video sequences still remains challenging. In existing systems, either the motion models are oversimplified or important factors such as blur kernel and noise level are assumed to be known. Such models cannot capture the intrinsic characteristics that may differ from one sequence to another. In this paper, we propose a Bayesian approach to adaptive video super resolution via simultaneously estimating underlying motion, blur kernel, and noise level while reconstructing the original high-resolution frames. As a result, our system not only produces very promising super resolution results outperforming the state of the art, but also adapts to a variety of noise levels and blur kernels. To further analyze the effect of noise and blur kernel, we perform a two-step analysis using the Cramer-Rao bounds. We study how blur kernel and noise influence motion estimation with aliasing signals, how noise affects super resolution with perfect motion, and finally how blur kernel and noise influence super resolution with unknown motion. Our analysis results confirm empirical observations, in particular that an intermediate size blur kernel achieves the optimal image reconstruction results.},
author = {Liu, Ce and Sun, Deqing},
doi = {10.1109/TPAMI.2013.127},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Pattern Analysis and Machine Intelligence/2014\_On bayesian adaptive video super resolution.pdf:pdf},
isbn = {2012120962},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Super resolution,aliasing,blur kernel,noise level,optical flow},
number = {2},
pages = {346--360},
pmid = {24356354},
title = {{On bayesian adaptive video super resolution}},
volume = {36},
year = {2014}
}
@article{Su2011,
abstract = {Video super-resolution can be generally divided into two categories: incremental video super-resolution and simultaneous video super-resolution. Incremental video super-resolution algorithms are usually faster, but their results cannot be guaranteed to be visually consistent to the human vision system. An adaptive incremental video super-resolution framework with the temporal consistency constraint is proposed in this paper. The temporal consistency among the video frames is enforced by imposing the similarity between the adjacent reconstructed HR frames. The variances of the potential functions, which affect the weights of the different terms in the utility function, are adaptively determined so that the algorithm is robust to various motion and image content situations. Some considerations, such as the incremental motion estimation, are also incorporated to improve the efficiency of the algorithm, which makes the proposed algorithm near-realtime. The experimental results show that the proposed algorithm can generate HR video with high quality while saving the computational time as well.},
author = {Su, Heng and Wu, Ying and Zhou, Jie},
doi = {10.1109/ICIP.2011.6115632},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings - International Conference on Image Processing, ICIP/2011\_Adaptive incremental video super-resolution with temporal consistency.pdf:pdf},
isbn = {9781457713033},
issn = {15224880},
journal = {Proceedings - International Conference on Image Processing, ICIP},
keywords = {Video super-resolution,adaptive framework,human vision system,temporal consistency},
pages = {1149--1152},
title = {{Adaptive incremental video super-resolution with temporal consistency}},
year = {2011}
}
@article{Engineering2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1302.3446v2},
author = {Engineering, Computer},
eprint = {arXiv:1302.3446v2},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2013\_ADAPTIVE TEMPORAL COMPRESSIVE SENSING FOR VIDEO Xin Yuan , Jianbo Yang , Patrick Llull , Xuejun Liao , Guillermo Sapiro , David J ..pdf:pdf},
isbn = {9781479923410},
pages = {14--18},
title = {{ADAPTIVE TEMPORAL COMPRESSIVE SENSING FOR VIDEO Xin Yuan , Jianbo Yang , Patrick Llull , Xuejun Liao , Guillermo Sapiro , David J . Brady and Lawrence Carin}},
year = {2013}
}
