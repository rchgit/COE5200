@article{Nyquist1928,
abstract = {The most obvious method for determining the distortion of telegraph signals is to calculate the transients of the telegraph system. This method has been treated by various writers, and solutions are available for telegraph lines with simple terminal conditions. It is well known that the extension of the same methods to more complicated terminal conditions, which represent the usual terminal apparatus, leads to great difficulties. The present paper attacks the same problem from the alternative standpoint of the steady-state characteristics of the system. This method has the advantage over the method of transients that the complication of the circuit which results from the use of terminal apparatus does not complicate the calculations materially. This method of treatment necessitates expressing the criteria of distortionless transmission in terms of the steady-state characteristics. Accordingly, a considerable portion of the paper describes and illustrates a method for making this translation. A discussion is given of the minimum frequency range required for transmission at a given speed of signaling. In the case of carrier telegraphy, this discussion includes a comparison of single-sideband and double-sideband transmission. A number of incidental topics is also discussed},
author = {Nyquist, H.},
doi = {10.1109/5.989875},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Proceedings of the IEEE/1928\_Certain topics in telegraph transmission theory.pdf:pdf},
isbn = {0096-3860},
issn = {00189219},
journal = {Proceedings of the IEEE},
number = {2},
pages = {280--305},
title = {{Certain topics in telegraph transmission theory}},
volume = {90},
year = {1928}
}
@book{WikiBook2010,
author = {WikiBook},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2010\_Image processing.pdf:pdf},
isbn = {1846283795},
number = {May},
title = {{Image processing}},
year = {2010}
}
@book{Vetterli2014,
author = {Vetterli, Martin and Kovacevic, Jelena and Goyal, Vivek K.},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/Unknown/2014\_Foundations of Signal Processing.pdf:pdf},
isbn = {110703860X},
number = {May},
pages = {650},
title = {{Foundations of Signal Processing}},
url = {http://www.amazon.co.uk/Foundations-Signal-Processing-Martin-Vetterli/dp/110703860X},
year = {2014}
}
@article{Vetterli2010,
abstract = {The aim of this book is to provide a set of tools for users of state-of-the-art signal processing technology and a solid foundation for those hoping to advance the the- ory and practice of signal processing. Many of the results and techniques presented here, while rooted in classic Fourier techniques for signal representation, first ap- peared during a flurry of activity in the 1980s and 1990s. New constructions for local Fourier transforms and orthonormal wavelet bases during that period weremo- tivated both by theoretical interest and by applications, in particular in multimedia communications. New bases with specified time–frequency behavior were found, with impact well beyond the original fields of application. Areas as diverse as com- puter graphics and numerical analysis embraced some of the new constructions—no surprise given the pervasive role of Fourier analysis in science and engineering. Now that the dust has settled, some of what was new and esoteric is now fundamental. Our motivation is to bring these new fundamentals to a broader audience to further expand their impact. We thus provide an integrated view of classical Fourier analysis of signals and systems alongside structured representations with time–frequency locality and their myriad of applications.},
author = {Vetterli, Martin and Kovacevic, Jelena and Goyal, Vivek K.},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/October/2010\_Fourier and Wavelet Signal Processing.pdf:pdf},
isbn = {10703860X},
journal = {October},
number = {October},
pages = {1--761},
title = {{Fourier and Wavelet Signal Processing}},
year = {2010}
}
@article{Zhang2011a,
author = {Zhang, Lin and Zhang, Lei and Mou, Xuanqin and Zhang, David},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2011\_FSIM A Feature Similarity Index for Image Quality Assessment.pdf:pdf},
journal = {IEEE Transactions on Image Processing},
keywords = {Zhang2011a},
number = {8},
pages = {2378--2386},
title = {{FSIM : A Feature Similarity Index for Image Quality Assessment}},
volume = {20},
year = {2011}
}
@article{Brown1992,
abstract = {Registration is a fundamental task in image processing used to match two or more pictures taken, for example, at different times, from different sensors, or from different viewpoints. Virtually all large systems which evaluate images require the registration of images, or a closely related operation, as an intermediate step. Specific examples of systems where image registration is a significant component include matching a target with a real-time image of a scene for target recognition, monitoring global land usage using satellite images, matching stereo images to recover shape for autonomous navigation, and aligning images from different medical modalities for diagnosis. Over the years, a broad range of techniques has been developed for various types of data and problems. These techniques have been independently studied for several different applications, resulting in a large body of research. This paper organizes this material by establishing the relationship between the variations in the images and the type of registration techniques which can most appropriately be applied. Three major types of variations are distinguished. The first type are the variations due to the differences in acquisition which cause the images to be misaligned. To register images, a spatial transformation is found which will remove these variations. The class of transformations which must be searched to find the optimal transformation is determined by knowledge about the variations of this type. The transformation class in turn influences the general technique that should be taken. The second type of variations are those which are also due to differences in acquisition, but cannot be modeled easily such as lighting and atmospheric conditions. This type usually effects intensity values, but they may also be spatial, such as perspective distortions. The third type of variations are differences in the images that are of interest such as object movements, growths, or other scene changes. Variations of the second and third type are not directly removed by registration, but they make registration more difficult since an exact match is no longer possible. In particular, it is critical that variations of the third type are not removed. Knowledge about the characteristics of each type of variation effect the choice of feature space, similarity measure, search space, and search strategy which will make up the final technique. All registration techniques can be viewed as different combinations of these choices. This framework is useful for understanding the merits and relationships between the wide variety of existing techniques and for assisting in the selection of the most suitable technique for a specific problem.},
author = {Brown, Lisa Gottesfeld},
doi = {10.1145/146370.146374},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/ACM Computing Surveys/1992\_A survey of image registration techniques(2).pdf:pdf},
isbn = {0360-0300},
issn = {03600300},
journal = {ACM Computing Surveys},
number = {4},
pages = {325--376},
pmid = {17427731},
title = {{A survey of image registration techniques}},
volume = {24},
year = {1992}
}
@article{Robinson2004,
abstract = {The task of image registration is fundamental in image processing. It often is a critical preprocessing step to many modern image processing and computer vision tasks, and many algorithms and techniques have been proposed to address the registration problem. Often, the performances of these techniques have been presented using a variety of relative measures comparing different estimators, leaving open the critical question of overall optimality. In this paper, we present the fundamental performance limits for the problem of image registration as derived from the Cramer–Rao inequality. We compare the experimental performance of several popular methods with respect to this performance bound, and explain the fundamental tradeoff between variance and bias inherent to the problem of image registration. In particular, we derive and explore the bias of the popular gradient-based estimator showing how widely used multiscale methods for improving performance can be explained with this bias expression. Finally, we present experimental simulations showing the general rule-of-thumb performance limits for gradient-based image registration techniques.},
author = {Robinson, Dirk and Member, Student and Milanfar, Peyman and Member, Senior},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/IEEE Transactions on Image Processing/2004\_Fundamental performance limits in image registration.pdf:pdf},
journal = {IEEE Transactions on Image Processing},
keywords = {Bias,Cramer–Rao bound,Fisher,error analysis,gradient methods,image registration,information,motion estimation,optical flow,performance limits},
number = {9},
pages = {1185--1199},
title = {{Fundamental performance limits in image registration}},
volume = {13},
year = {2004}
}
@article{Weken2002,
abstract = { Objective quality measures or measures of comparison are of great importance in the field of image processing. These measures can be useful for the evaluation and comparison of different algorithms; designed to solve a particular problem. For example, one of the possible applications is the comparison of different filters for image noise reduction. It is well-known that classical quality measures, such as the MSE (mean square error) or the PSNR (peak signal to noise ratio), do not always correspond to visual observations. Therefore, several researchers are - and have been - looking for new quality measures, better adapted to human perception. The existing similarity measures are all pixel-based, and have therefore not always satisfactory results. To cope with this drawback, we propose a similarity measure based on a neighbourhood, so that the relevant structures of the images are observed very well. The new similarity measure is designed especially for use in image processing.},
author = {Weken, D. Van Der and Nachtegael, M. and Kerre, E.E.},
doi = {10.1109/ICOSP.2002.1181155},
file = {:C$\backslash$:/Users/Reich/Documents/Mendeley Desktop/6th International Conference on Signal Processing, 2002/2002\_Image quality evaluation.pdf:pdf},
isbn = {0-7803-7488-6},
journal = {6th International Conference on Signal Processing, 2002.},
pages = {2--5},
title = {{Image quality evaluation}},
volume = {1},
year = {2002}
}
